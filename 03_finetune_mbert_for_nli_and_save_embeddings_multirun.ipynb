{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "VlYo1CIaQLY7"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:2\"\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(13370)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",sentence1,sentence2,gold_label,sent1_readable,sent2_readable,sent1_subj_quant,sent1_subj_adj,sent1_obj_quant,sent1_obj_adj,sent1_adv,sent1_polarity,sent2_subj_quant,sent2_subj_adj,sent2_obj_quant,sent2_obj_adj,sent2_adv,sent2_polarity\r\n",
      "8,some slow gymnast emptystring emptystring publicizes notevery emptystring straw,some emptystring gymnast emptystring jealously publicizes every opaque straw,neutral,some slow gymnast publicizes not every straw,some gymnast jealously publicizes every opaque straw,some,yes,notevery,no,no,aff,some,no,every,yes,yes,aff\r\n",
      "12,no Spanish receiver emptystring emptystring publicizes some dry lemur,every emptystring receiver emptystring fortunately publicizes every dry lemur,contradiction,no spanish receiver publicizes some dry lemur,every receiver fortunately publicizes every dry lemur,no,yes,some,yes,no,aff,every,no,every,yes,yes,aff\r\n",
      "13,no furry linguist emptystring deftly draws no pink lemur,every furry linguist emptystring deftly draws every emptystring lemur,neutral,no furry linguist deftly draws no pink lemur,every furry linguist deftly draws every lemur,no,yes,no,yes,yes,aff,every,yes,every,no,yes,aff\r\n",
      "24,every terrible chef emptystring poorly claims every emptystring crown,no terrible chef emptystring emptystring claims every soft crown,contradiction,every terrible chef poorly claims every crown,no terrible chef claims every soft crown,every,yes,every,no,yes,aff,no,yes,every,yes,no,aff\r\n",
      "27,no friendly princess emptystring absentmindedly receives notevery Mexican keyboard,every emptystring princess emptystring absentmindedly receives no Mexican dog,neutral,no friendly princess absentmindedly receives not every mexican keyboard,every princess absentmindedly receives no mexican dog,no,yes,notevery,yes,yes,aff,every,no,no,yes,yes,aff\r\n",
      "34,no emptystring milkman emptystring wearily faces no smelly harp,some Californian milkman emptystring emptystring faces no emptystring harp,contradiction,no milkman wearily faces no smelly harp,some californian milkman faces no harp,no,no,no,yes,yes,aff,some,yes,no,no,no,aff\r\n",
      "37,notevery slimy clown emptystring wildly washes some emptystring mug,notevery emptystring clown emptystring emptystring washes every common mug,neutral,not every slimy clown wildly washes some mug,not every clown washes every common mug,notevery,yes,some,no,yes,aff,notevery,no,every,yes,no,aff\r\n",
      "39,notevery Chinese playwright emptystring deftly slaps every cyan bag,no Chinese playwright emptystring deftly slaps notevery cyan bag,contradiction,not every chinese playwright deftly slaps every cyan bag,no chinese playwright deftly slaps not every cyan bag,notevery,yes,every,yes,yes,aff,no,yes,notevery,yes,yes,aff\r\n",
      "43,notevery emptystring traitor emptystring mysteriously receives notevery Japanese pillow,no French traitor emptystring roughly reveres some emptystring pillow,neutral,not every traitor mysteriously receives not every japanese pillow,no french traitor roughly reveres some pillow,notevery,no,notevery,yes,yes,aff,no,yes,some,no,yes,aff\r\n"
     ]
    }
   ],
   "source": [
    "!head stage1_training_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 sent1_subj_adj\n",
    "# 9 sent1_obj_adj\n",
    "# 10 sent1_adv,sent1_polarity,sent2_subj_quant,sent2_subj_adj,sent2_obj_quant,sent2_obj_adj,sent2_adv,sent2_polarity\n",
    "\n",
    "sadj1 = set()\n",
    "subj1 = set()\n",
    "adv1 = set()\n",
    "verb1 = set()\n",
    "oadj1 = set()\n",
    "obj1 = set()\n",
    "\n",
    "sadj2 = set()\n",
    "subj2 = set()\n",
    "adv2 = set()\n",
    "verb2 = set()\n",
    "oadj2 = set()\n",
    "obj2 = set()\n",
    "\n",
    "for idx, line in enumerate(open('stage1_training_data.csv')):\n",
    "    if idx:\n",
    "        chunks = line.strip().split(',')\n",
    "        assert len(chunks)==18, 'parse error'\n",
    "        words = chunks[1].split()\n",
    "        sadj1.add(words[1])\n",
    "        subj1.add(words[2])\n",
    "        adv1.add(words[4])\n",
    "        verb1.add(words[5])\n",
    "        oadj1.add(words[7])\n",
    "        obj1.add(words[8])\n",
    "        words = chunks[2].split()\n",
    "        sadj2.add(words[1])\n",
    "        subj2.add(words[2])\n",
    "        adv2.add(words[4])\n",
    "        verb2.add(words[5])\n",
    "        oadj2.add(words[7])\n",
    "        obj2.add(words[8])\n",
    "\n",
    "set_random_seed(0xABBA+1)\n",
    "\n",
    "sadjs = list(sadj1-set(('emptystring',)))\n",
    "np.random.shuffle(sadjs)\n",
    "\n",
    "subjs = list(subj1-set(('emptystring',)))\n",
    "np.random.shuffle(subjs)\n",
    "\n",
    "objs = list(obj1-set(('emptystring',)))\n",
    "np.random.shuffle(objs)\n",
    "\n",
    "advs = list(adv1-set(('emptystring',)))\n",
    "np.random.shuffle(advs)\n",
    "\n",
    "oadjs = list(oadj1-set(('emptystring',)))\n",
    "np.random.shuffle(oadjs)\n",
    "\n",
    "verbs = list(verb1-set(('emptystring',)))\n",
    "np.random.shuffle(verbs)\n",
    "\n",
    "TRAIN_PART = 60\n",
    "VALID_PART = 1000\n",
    "\n",
    "train_sadjs = sadjs[:TRAIN_PART]+['emptystring',]\n",
    "train_subjs = subjs[:TRAIN_PART]+['emptystring',]\n",
    "train_objs = objs[:TRAIN_PART]+['emptystring',]\n",
    "train_advs = advs[:TRAIN_PART]+['emptystring',]\n",
    "train_oadjs = oadjs[:TRAIN_PART]+['emptystring',]\n",
    "train_verbs = verbs[:TRAIN_PART]+['emptystring',]\n",
    "\n",
    "valid_sadjs = sadjs[TRAIN_PART:VALID_PART]+['emptystring',]\n",
    "valid_subjs = subjs[TRAIN_PART:VALID_PART]+['emptystring',]\n",
    "valid_objs =  objs[TRAIN_PART:VALID_PART]+['emptystring',]\n",
    "valid_advs =  advs[TRAIN_PART:VALID_PART]+['emptystring',]\n",
    "valid_oadjs = oadjs[TRAIN_PART:VALID_PART]+['emptystring',]\n",
    "valid_verbs = verbs[TRAIN_PART:VALID_PART]+['emptystring',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beautiful', 'terrible', 'scaly', 'savvy', 'preposterous', 'slow', 'charismatic', 'Mongolian', 'untrustworthy', 'friendly', 'lucky', 'fuzzy', 'furry', 'antagonistic', 'Israeli', 'Italian', 'Texan', 'Korean', 'Latvian', 'stupid', 'unhelpful', 'rough', 'Panamanian', 'Mexican', 'Nebraskan', 'uncouth', 'Chinese', 'kooky', 'wild', 'sheltered', 'sneaky', 'coy', 'small', 'irresistible', 'loving', 'French', 'sly', 'Indian', 'Austrian', 'jealous', 'Spanish', 'insane', 'vivacious', 'happy', 'idealistic', 'Moroccan', 'rude', 'angry', 'Ukranian', 'devout', 'Pakistani', 'Canadian', 'big', 'polite', 'chummy', 'soft', 'surly', 'scatterbrained', 'taciturn', 'seductive', 'emptystring']\n",
      "['outstanding', 'unpredictable', 'boisterous', 'thoughtful', 'Oklahoman', 'Alabaman', 'religious', 'helpful', 'talkative', 'smooth', 'Afghani', 'noble', 'proud', 'silly', 'Columbian', 'Siberian', 'crazy', 'Hawaiian', 'Oregonian', 'English', 'Indonesian', 'Alaskan', 'Mississippian', 'Californian', 'unhinged', 'horrifying', 'German', 'Washingtonian', 'sad', 'hopeful', 'quick', 'Polish', 'Swiss', 'Japanese', 'burly', 'slimy', 'underwhelming', 'loud', 'ugly', 'Lithuanian', 'emptystring']\n"
     ]
    }
   ],
   "source": [
    "print(train_sadjs)\n",
    "print(valid_sadjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "475998\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "\n",
    "for idx, line in enumerate(open('stage1_training_data.csv')):\n",
    "    if idx:\n",
    "        chunks = line.strip().split(',')\n",
    "        assert len(chunks)==18, 'parse error'\n",
    "        records.append( {'left':chunks[4], 'right': chunks[5], 'label':chunks[3]})\n",
    "\n",
    "np.random.shuffle(records)\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19806\n"
     ]
    }
   ],
   "source": [
    "train_records = []\n",
    "\n",
    "for idx, line in enumerate(open('stage1_training_data.csv')):\n",
    "    if idx:\n",
    "        chunks = line.strip().split(',')\n",
    "        assert len(chunks)==18, 'parse error'\n",
    "        words = chunks[1].split()\n",
    "        if  words[1] not in train_sadjs or \\\n",
    "            words[2] not in train_subjs or \\\n",
    "            words[4] not in train_advs or \\\n",
    "            words[5] not in train_verbs or \\\n",
    "            words[7] not in train_oadjs or \\\n",
    "            words[8] not in train_objs: continue\n",
    "        words = chunks[2].split()\n",
    "        if  words[1] not in train_sadjs or \\\n",
    "            words[2] not in train_subjs or \\\n",
    "            words[4] not in train_advs or \\\n",
    "            words[5] not in train_verbs or \\\n",
    "            words[7] not in train_oadjs or \\\n",
    "            words[8] not in train_objs: continue\n",
    "        train_records.append( {'left':chunks[4], 'right': chunks[5], 'label':chunks[3]})\n",
    "\n",
    "np.random.shuffle(train_records)\n",
    "print(len(train_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3503\n"
     ]
    }
   ],
   "source": [
    "val_records = []\n",
    "\n",
    "for idx, line in enumerate(open('stage1_training_data.csv')):\n",
    "    if idx:\n",
    "        chunks = line.strip().split(',')\n",
    "        assert len(chunks)==18, 'parse error'\n",
    "        words = chunks[1].split()\n",
    "        if  words[1] not in valid_sadjs or \\\n",
    "            words[2] not in valid_subjs or \\\n",
    "            words[8] not in valid_objs: continue\n",
    "        words = chunks[2].split()\n",
    "        if  words[1] not in valid_sadjs or \\\n",
    "            words[2] not in valid_subjs or \\\n",
    "            words[4] not in valid_advs or \\\n",
    "            words[5] not in valid_verbs or \\\n",
    "            words[7] not in valid_oadjs or \\\n",
    "            words[8] not in valid_objs: continue\n",
    "        val_records.append( {'left':chunks[4], 'right': chunks[5], 'label':chunks[3]})\n",
    "\n",
    "np.random.shuffle(val_records)\n",
    "print(len(val_records))\n",
    "# val_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751 1752\n"
     ]
    }
   ],
   "source": [
    "test_records = val_records[:len(val_records)//2]\n",
    "val_records = val_records[-len(val_records)//2:]\n",
    "print(len(test_records), len(val_records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_SHARE = .1\n",
    "TEST_SHARE = .1\n",
    "\n",
    "val_records = records[:int(len(records)*VAL_SHARE)]\n",
    "test_records = records[-int(len(records)*TEST_SHARE):]\n",
    "train_records = records[int(len(records)*VAL_SHARE):-int(len(records)*TEST_SHARE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN65SEFpOOmI",
    "outputId": "858b9f6f-a215-4175-8ef1-0d259ebeb1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'contradiction': 319508, 'neutral': 317800, 'entailment': 314688}) 951996\n",
      "['neutral', 'entailment', 'contradiction']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "labels_counter = Counter([r[\"label\"] for r in records])\n",
    "print(labels_counter, sum(labels_counter.values()))\n",
    "labels = list(labels_counter.keys())\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class NLIsDataset(Dataset):\n",
    "    def __init__(self, records, tokenizer, max_tokens, labels):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_tokens = max_tokens\n",
    "        self.records = records\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.records)\n",
    "    \n",
    "    def embed_record(self, record):\n",
    "        inputs = self.tokenizer(\n",
    "            text=record[\"left\"],\n",
    "            text_pair=record[\"right\"],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_tokens,\n",
    "            padding=\"max_length\",\n",
    "            truncation=\"longest_first\",\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        for key, value in inputs.items():\n",
    "            value.squeeze_(0)\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        record = self.records[index]\n",
    "        output = self.embed_record(record)\n",
    "        label = record.get(\"label\", None)\n",
    "        if label is not None and label in self.labels:\n",
    "            output[\"labels\"] = torch.tensor(self.labels.index(label))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-uncased'\n",
    "TOKENIZER_NAME = MODEL_NAME\n",
    "MAX_TOKENS = 100\n",
    "EPOCHS = 4*32 # 4\n",
    "EVAL_STEPS = 32*4 # 32\n",
    "WARMUP_STEPS = 16\n",
    "LR = 0.00002\n",
    "BATCH_SIZE = 32*4 # 32\n",
    "GRAD_ACCUM_STEPS = 1 # 4\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, do_lower_case=False)\n",
    "train_data = NLIsDataset(train_records, tokenizer, MAX_TOKENS, labels)\n",
    "val_data = NLIsDataset(val_records, tokenizer, MAX_TOKENS, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wIxaG3SBS9z-",
    "outputId": "7144b605-71e0-4b65-8b74-c2a575a21622",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/pytorch_model.bin from cache at /home/altsoph/.cache/huggingface/transformers/37f730c9dc4fc13ab6bf412fdc0ad936241a39a70628c2d4a85a607ea775b865.a458b2dad7b293099dd815628e032e6c22519889d75f13d6f244dbe068525a56\n",
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19806\n",
      "  Num Epochs = 128\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 19840\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='19840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 1280/19840 17:12 < 4:09:56, 1.24 it/s, Epoch 8/128]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.877400</td>\n",
       "      <td>0.671406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.650700</td>\n",
       "      <td>0.649886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.589700</td>\n",
       "      <td>0.527260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.525900</td>\n",
       "      <td>0.523474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.531081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>768</td>\n",
       "      <td>0.522200</td>\n",
       "      <td>0.519647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>896</td>\n",
       "      <td>0.523400</td>\n",
       "      <td>0.518913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1024</td>\n",
       "      <td>0.514800</td>\n",
       "      <td>0.523163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1152</td>\n",
       "      <td>0.507900</td>\n",
       "      <td>0.522633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.505400</td>\n",
       "      <td>0.547371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-128\n",
      "Configuration saved in checkpoints/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints/checkpoint-128/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-256\n",
      "Configuration saved in checkpoints/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-384\n",
      "Configuration saved in checkpoints/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-512\n",
      "Configuration saved in checkpoints/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-640\n",
      "Configuration saved in checkpoints/checkpoint-640/config.json\n",
      "Model weights saved in checkpoints/checkpoint-640/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-768\n",
      "Configuration saved in checkpoints/checkpoint-768/config.json\n",
      "Model weights saved in checkpoints/checkpoint-768/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-512] due to args.save_total_limit\n",
      "Deleting older checkpoint [checkpoints/checkpoint-640] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-896\n",
      "Configuration saved in checkpoints/checkpoint-896/config.json\n",
      "Model weights saved in checkpoints/checkpoint-896/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-768] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-1024\n",
      "Configuration saved in checkpoints/checkpoint-1024/config.json\n",
      "Model weights saved in checkpoints/checkpoint-1024/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-1152\n",
      "Configuration saved in checkpoints/checkpoint-1152/config.json\n",
      "Model weights saved in checkpoints/checkpoint-1152/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-1024] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1752\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints/checkpoint-1280\n",
      "Configuration saved in checkpoints/checkpoint-1280/config.json\n",
      "Model weights saved in checkpoints/checkpoint-1280/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints/checkpoint-1152] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints/checkpoint-896 (score: 0.5189130902290344).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1280, training_loss=0.5745137512683869, metrics={'train_runtime': 1033.3974, 'train_samples_per_second': 2453.236, 'train_steps_per_second': 19.199, 'total_flos': 1.64247189621984e+16, 'train_loss': 0.5745137512683869, 'epoch': 8.26})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, EarlyStoppingCallback\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(labels))\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"checkpoints\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    logging_steps=EVAL_STEPS,\n",
    "    save_steps=EVAL_STEPS,\n",
    "    warmup_steps=WARMUP_STEPS,\n",
    "    learning_rate=LR,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "!rm -rf checkpoints\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def get_batch(data, batch_size):\n",
    "    start_index = 0\n",
    "    while start_index < len(data):\n",
    "        end_index = start_index + batch_size\n",
    "        batch = data[start_index:end_index]\n",
    "        yield batch\n",
    "        start_index = end_index\n",
    "\n",
    "def pipe_predict(data, pipe, batch_size=64):\n",
    "    raw_preds = []\n",
    "    for batch in tqdm(get_batch(data, batch_size)):\n",
    "        raw_preds += pipe(batch)\n",
    "    preds = np.array([int(max(labels, key=lambda x: x[\"score\"])[\"label\"][-1]) for labels in raw_preds])\n",
    "    pp = np.array([[l[\"score\"] for l in labels] for labels in raw_preds])\n",
    "    return preds, pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769a5bdf64d64ed79e1ff1803ee69d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.992     0.761     0.861       494\n",
      "           1      0.591     0.932     0.723       633\n",
      "           2      0.759     0.455     0.569       624\n",
      "\n",
      "    accuracy                          0.714      1751\n",
      "   macro avg      0.781     0.716     0.718      1751\n",
      "weighted avg      0.764     0.714     0.707      1751\n",
      "\n",
      "[[376  69  49]\n",
      " [  2 590  41]\n",
      " [  1 339 284]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "model.eval()\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0, return_all_scores=True)\n",
    "\n",
    "y_true = np.array([labels.index(r[\"label\"]) for r in test_records], dtype=np.int32)\n",
    "test_pairs = [(r[\"left\"], r[\"right\"]) for r in test_records]\n",
    "\n",
    "y_pred, y_pred_prob = pipe_predict(test_pairs, pipe)\n",
    "\n",
    "print(classification_report(y_true, y_pred, digits=3))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 14:52:02.310903: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "### load model\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, EarlyStoppingCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "records2 = []\n",
    "\n",
    "for idx, line in enumerate(open('stage2_training_data.csv')):\n",
    "    if idx:\n",
    "        chunks = line.strip().split(',')\n",
    "        assert len(chunks)==18, 'parse error'\n",
    "        records2.append( {'left':chunks[4], 'right': chunks[5], 'label':chunks[3]})\n",
    "\n",
    "np.random.shuffle(records2)\n",
    "# records2[:5]\n",
    "VAL_SHARE = .1\n",
    "TEST_SHARE = .1\n",
    "\n",
    "val_records2 = records2[:int(len(records2)*VAL_SHARE)]\n",
    "test_records2 = records2[-int(len(records2)*TEST_SHARE):]\n",
    "train_records2 = records2[int(len(records2)*VAL_SHARE):-int(len(records2)*TEST_SHARE)]\n",
    "\n",
    "# tokenizer.convert_ids_to_tokens(val_data2[0]['input_ids'])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS = 100\n",
    "EPOCHS = 4 # 4\n",
    "EVAL_STEPS = 32 # 32\n",
    "WARMUP_STEPS = 16\n",
    "LR = 0.00002\n",
    "BATCH_SIZE = 32*4 # 32\n",
    "GRAD_ACCUM_STEPS = 1 # 4\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:08 < 05:03, 0.82 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.473604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.433418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.294437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.268062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>0.267965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.251500</td>\n",
       "      <td>0.259124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.251100</td>\n",
       "      <td>0.256302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.258736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>0.257354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222400</td>\n",
       "      <td>0.263167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2563023865222931).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a4d808eb34c42c4899d54dc661895fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.996     0.887     0.938       781\n",
      "           1      0.866     0.923     0.893       944\n",
      "           2      0.844     0.873     0.858       675\n",
      "\n",
      "    accuracy                          0.897      2400\n",
      "   macro avg      0.902     0.894     0.897      2400\n",
      "weighted avg      0.902     0.897     0.898      2400\n",
      "\n",
      "[[693  52  36]\n",
      " [  0 871  73]\n",
      " [  3  83 589]]\n",
      "=== 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:52 < 01:13, 0.76 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca19dc968184c7cbe49742e6a410db3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 13:35, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fee9b89e1741bfadd0a8c069d9a61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 07:59 < 04:31, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6483d32a20d49798a45c6e003d733ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:07 < 05:03, 0.82 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea62166c786c47459665dc780c3df6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:05 < 01:08, 0.81 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd341332c50400e8d884f772086ee60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a9529632f744e280f3d4ac8a961f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 08:14 < 04:39, 0.77 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a537e96e4c9841ed82bb69286d879ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:17 < 05:10, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090cd50782b7468ebe5342ca4ffa6802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 13:24 < 01:23, 0.67 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5b6f660a4a4ef28d5a2551500c7d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 13:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa7741951d9431c93bcadee5d97c9a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 08:10 < 04:37, 0.78 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8f97bc47fb46b9a8eb5f8370831e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:19 < 05:11, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e7cba2431742d1b7618b37a401fe58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:09 < 01:09, 0.81 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecc523893c545f6a1cced1e39955a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:05, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10b3add8a7f4b178a4b01e13600955a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 08:04 < 04:34, 0.79 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcad18b4f194cfe888b0a27e068bb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:48 < 05:31, 0.75 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72a9b05f9e04ac982a064355dbf7e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 13:32 < 01:23, 0.67 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c115fddd86c48c180cbe80e0b1a7bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:10, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7611edbbfd1c4f63b1ea091e94c0ba7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 07:56 < 04:29, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd37ac1edbcf44ca912c16d196896533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:10 < 05:04, 0.81 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc58ec7de5e4f7db62833785dbf8838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:11 < 01:09, 0.81 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d4b9a7f4f3e410ba37a0c8096fadf97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2af4ed522b8a46d8bd958c5fdd68f5d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 07:56 < 04:29, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7799a8f5ec4772adb19b6fd058c06d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 08:46 < 06:12, 0.66 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab5ee154feb4beba0e03d65de9ae7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 12:44 < 01:19, 0.71 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba767c1b38454f0eb3446d4de007b4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "192ac8514b0e4ae88a97aaffa7d5d5ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 07:40 < 04:20, 0.83 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08a8f4ab9994bb3b1633be4f442bddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:02 < 04:59, 0.83 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710ccf9640804824a143a108f4e94624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:01 < 01:08, 0.82 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b367148de0448b903976a3a3120b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 11:54, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b92852cad747549910ab39b15461f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 08:25 < 04:45, 0.76 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d400df552aea467bb4a2feddbc208626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 08:44 < 06:11, 0.67 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc5e676b743420ea7b69be0f56e9324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 11:57 < 01:14, 0.76 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47719b4ab2d341a5b5e8a6fcf5c961f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 12:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fb5f8dfb114c08a5d324f3841c65f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 07:57 < 04:30, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82efd758c4304c2eb7e96e9171d99ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n",
      "=== 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='352' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [352/600 07:17 < 05:10, 0.80 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.609100</td>\n",
       "      <td>0.485666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.471399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.466104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.437200</td>\n",
       "      <td>0.404997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.288111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.262900</td>\n",
       "      <td>0.269618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>0.260253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.249900</td>\n",
       "      <td>0.253421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.241400</td>\n",
       "      <td>0.257515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.232400</td>\n",
       "      <td>0.254189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.217900</td>\n",
       "      <td>0.260921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-256 (score: 0.2534206509590149).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa11b3e5a6b7429387721ee65fd4b205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.883     0.938       781\n",
      "           1      0.901     0.891     0.896       944\n",
      "           2      0.811     0.933     0.868       675\n",
      "\n",
      "    accuracy                          0.900      2400\n",
      "   macro avg      0.904     0.903     0.901      2400\n",
      "weighted avg      0.908     0.900     0.902      2400\n",
      "\n",
      "[[690  47  44]\n",
      " [  0 841 103]\n",
      " [  0  45 630]]\n",
      "=== 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='544' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [544/600 10:57 < 01:07, 0.82 it/s, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.576200</td>\n",
       "      <td>0.477370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.467086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.434319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.281600</td>\n",
       "      <td>0.271644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>0.274748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.256551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.247300</td>\n",
       "      <td>0.254168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.256164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234300</td>\n",
       "      <td>0.252852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.256411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.231600</td>\n",
       "      <td>0.251613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.240400</td>\n",
       "      <td>0.251190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.254102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>0.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.221400</td>\n",
       "      <td>0.254352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-448 (score: 0.25118961930274963).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fffb90c129447997b6c64c1194d440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.893     0.892     0.892       944\n",
      "           2      0.815     0.924     0.866       675\n",
      "\n",
      "    accuracy                          0.899      2400\n",
      "   macro avg      0.903     0.900     0.899      2400\n",
      "weighted avg      0.906     0.899     0.900      2400\n",
      "\n",
      "[[691  50  40]\n",
      " [  0 842 102]\n",
      " [  0  51 624]]\n",
      "=== 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 11:57, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.582300</td>\n",
       "      <td>0.481902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>0.473886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.467655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.445476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.388100</td>\n",
       "      <td>0.309914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.280694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>0.263402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.257509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.246300</td>\n",
       "      <td>0.256616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.236200</td>\n",
       "      <td>0.258732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.222800</td>\n",
       "      <td>0.258729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.238900</td>\n",
       "      <td>0.255119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>416</td>\n",
       "      <td>0.232200</td>\n",
       "      <td>0.254920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>448</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.255424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.224800</td>\n",
       "      <td>0.257060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.254346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>544</td>\n",
       "      <td>0.223200</td>\n",
       "      <td>0.257874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>576</td>\n",
       "      <td>0.222700</td>\n",
       "      <td>0.257483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-288] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-416\n",
      "Configuration saved in checkpoints2mr/checkpoint-416/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-416/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-448\n",
      "Configuration saved in checkpoints2mr/checkpoint-448/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-448/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-384] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-480\n",
      "Configuration saved in checkpoints2mr/checkpoint-480/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-480/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-448] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-512\n",
      "Configuration saved in checkpoints2mr/checkpoint-512/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-512/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-416] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-544\n",
      "Configuration saved in checkpoints2mr/checkpoint-544/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-544/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-480] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-576\n",
      "Configuration saved in checkpoints2mr/checkpoint-576/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-576/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-544] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-512 (score: 0.25434619188308716).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40be190170ac4a1aa214df671bd569ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.903     0.892     0.898       944\n",
      "           2      0.815     0.938     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.905     0.903      2400\n",
      "weighted avg      0.910     0.902     0.904      2400\n",
      "\n",
      "[[691  48  42]\n",
      " [  0 842 102]\n",
      " [  0  42 633]]\n",
      "=== 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/config.json from cache at /home/altsoph/.cache/huggingface/transformers/af4e101d208f361f141144dca21e9c4148aaf0e85441c2e335743d10829c6cad.d63adade93e44e64bedd306ec82ffd33eedabaf0ff08aabe581acaa48616a508\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/vocab.txt from cache at /home/altsoph/.cache/huggingface/transformers/269f2943d168a4cd2ddf3864cee89d7f7d78873b3d14a1229174d37212981a38.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer.json from cache at /home/altsoph/.cache/huggingface/transformers/857db185d48b92f3e6141ef5092d8d5dbebab7eef1bacc6c9eaf85cf23807641.73ad1f9fd9f94089672128003fb4a687b64b73b2bfb8d08766bbc71feec8cd96\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-uncased/resolve/main/tokenizer_config.json from cache at /home/altsoph/.cache/huggingface/transformers/1b935b135ddb021a7d836c00f5702b80d11d348fd5c5a42cbd933d8ed1f55be9.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file checkpoints/checkpoint-896/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "loading weights file checkpoints/checkpoint-896/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at checkpoints/checkpoint-896.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'every', 'thought', '##ful', 'w', '##his', '##tler', 'tac', '##itur', '##nl']\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 19200\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='384' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [384/600 09:01 < 05:06, 0.71 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.603000</td>\n",
       "      <td>0.488299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.468500</td>\n",
       "      <td>0.468142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>0.458383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.405200</td>\n",
       "      <td>0.329172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.271678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.269684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>0.256759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>256</td>\n",
       "      <td>0.248600</td>\n",
       "      <td>0.254095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>288</td>\n",
       "      <td>0.243100</td>\n",
       "      <td>0.253966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.234000</td>\n",
       "      <td>0.255008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>0.218300</td>\n",
       "      <td>0.259372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>384</td>\n",
       "      <td>0.230300</td>\n",
       "      <td>0.254998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-32\n",
      "Configuration saved in checkpoints2mr/checkpoint-32/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-32/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-512] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-64\n",
      "Configuration saved in checkpoints2mr/checkpoint-64/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-64/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-576] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-96\n",
      "Configuration saved in checkpoints2mr/checkpoint-96/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-96/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-32] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-128\n",
      "Configuration saved in checkpoints2mr/checkpoint-128/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-128/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-64] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-160\n",
      "Configuration saved in checkpoints2mr/checkpoint-160/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-160/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-96] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-192\n",
      "Configuration saved in checkpoints2mr/checkpoint-192/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-192/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-128] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-224\n",
      "Configuration saved in checkpoints2mr/checkpoint-224/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-224/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-160] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-256\n",
      "Configuration saved in checkpoints2mr/checkpoint-256/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-256/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-192] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-288\n",
      "Configuration saved in checkpoints2mr/checkpoint-288/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-288/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-320\n",
      "Configuration saved in checkpoints2mr/checkpoint-320/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-320/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-256] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-352\n",
      "Configuration saved in checkpoints2mr/checkpoint-352/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-352/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-320] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 2400\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to checkpoints2mr/checkpoint-384\n",
      "Configuration saved in checkpoints2mr/checkpoint-384/config.json\n",
      "Model weights saved in checkpoints2mr/checkpoint-384/pytorch_model.bin\n",
      "Deleting older checkpoint [checkpoints2mr/checkpoint-352] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from checkpoints2mr/checkpoint-288 (score: 0.2539660632610321).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e286fbac216a417ea4416f45d0d35cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      1.000     0.885     0.939       781\n",
      "           1      0.920     0.874     0.896       944\n",
      "           2      0.798     0.960     0.872       675\n",
      "\n",
      "    accuracy                          0.902      2400\n",
      "   macro avg      0.906     0.906     0.902      2400\n",
      "weighted avg      0.912     0.902     0.903      2400\n",
      "\n",
      "[[691  45  45]\n",
      " [  0 825 119]\n",
      " [  0  27 648]]\n"
     ]
    }
   ],
   "source": [
    "for run in range(40):\n",
    "    print('===',run)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, do_lower_case=False)\n",
    "    tokenizer.add_tokens(['[NOT]','[FEW]','[MANY]'], special_tokens=True)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('checkpoints/checkpoint-896', num_labels=len(labels))\n",
    "    model = model.to(\"cuda\")\n",
    "    model.resize_token_embeddings(len(tokenizer))    \n",
    "    \n",
    "    train_data2 = NLIsDataset(train_records2, tokenizer, MAX_TOKENS, labels)\n",
    "    val_data2 = NLIsDataset(val_records2, tokenizer, MAX_TOKENS, labels)\n",
    "\n",
    "    print(tokenizer.convert_ids_to_tokens(val_data2[0]['input_ids'])[:10])\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=PATIENCE)]\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"checkpoints2mr\",\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        logging_steps=EVAL_STEPS,\n",
    "        save_steps=EVAL_STEPS,\n",
    "        warmup_steps=WARMUP_STEPS,\n",
    "        learning_rate=LR,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        gradient_accumulation_steps=GRAD_ACCUM_STEPS,\n",
    "        report_to=\"none\",\n",
    "        load_best_model_at_end=True,\n",
    "        save_total_limit=2\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data2,\n",
    "        eval_dataset=val_data2,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    !rm -rf checkpoints2\n",
    "    trainer.train()    \n",
    "    \n",
    "    model.eval()\n",
    "    pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, framework=\"pt\", device=0, return_all_scores=True)\n",
    "\n",
    "    y_true2 = np.array([labels.index(r[\"label\"]) for r in test_records2], dtype=np.int32)\n",
    "    test_pairs2 = [(r[\"left\"], r[\"right\"]) for r in test_records2]\n",
    "\n",
    "    y_pred2, y_pred_prob2 = pipe_predict(test_pairs2, pipe)\n",
    "\n",
    "    print(classification_report(y_true2, y_pred2, digits=3))\n",
    "    print(confusion_matrix(y_true2, y_pred2))    \n",
    "    \n",
    "    not_embd = model.bert.embeddings.word_embeddings.weight.data[[tokenizer.vocab['[NOT]']]] # .cpu().detach().numpy())\n",
    "    few_embd = model.bert.embeddings.word_embeddings.weight.data[[tokenizer.vocab['[FEW]']]]\n",
    "    many_embd = model.bert.embeddings.word_embeddings.weight.data[[tokenizer.vocab['[MANY]']]]\n",
    "\n",
    "    np.savetxt(f'embd.not.mbert.{run:02}.txt', not_embd.cpu().detach().numpy())\n",
    "    np.savetxt(f'embd.few.mbert.{run:02}.txt', few_embd.cpu().detach().numpy())\n",
    "    np.savetxt(f'embd.many.mbert.{run:02}.txt', many_embd.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNrG+MkaPbNGzb8ySmY1mL3",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "HeadlineCause.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0157731fa2bc462f869e00544ddd24d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_954283fe5e0e415b9845f216cc6819b7",
       "IPY_MODEL_5da582397fbf4680ba6e556d8a889090",
       "IPY_MODEL_981fc4580f65438496be46ec2831c01d"
      ],
      "layout": "IPY_MODEL_bb7d334cf7424f1f87d8a6b3c87416e3"
     }
    },
    "0237d6c8e31b4cb88efc3c554fa503e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6643e46efdb7407684b825dcbc96a6b0",
      "max": 7347,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3d9bf8111fdf4473a0214e73c8f0904f",
      "value": 7347
     }
    },
    "0274a05891e342848be192f8046244b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_06f50b846e0b4d798f9539d231d8d73e",
       "IPY_MODEL_8f88412ed9d242af9be0fec29653e18f",
       "IPY_MODEL_3832ea9863dd45deb009574adcc157b9"
      ],
      "layout": "IPY_MODEL_7e1ea7d4b4454449bec0960459cc9f53"
     }
    },
    "028607648b6546cbaec8cd737fb5f584": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03908fdee9b646ae8074f28d864f933b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a84c592c55448b88ff4d4973c451ce6",
       "IPY_MODEL_97ca56c9528e41e3af81fffea441bd4c",
       "IPY_MODEL_e34c2879a0c94f468c41b7896b237d90"
      ],
      "layout": "IPY_MODEL_db4da210dd184d53a2c92a57671c7d79"
     }
    },
    "03ac9a49e4774957b3c603ab4a7b0f5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03d8bee45e714172852ecb9da7993627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "040a43c0a80749aa91c84e60c9dc9df1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0444bbfb1d5540c8a861fbaa402623a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "045560d87382405097639dde6aab8468": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "055bffbf4c6e45ec8c64af3516387d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09d31effa8eb47cead0c7c2694a7081a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8a1dd233b8ec4c869d459611281790e6",
      "value": 1
     }
    },
    "05bd42bf76cf4a8bb149287688d320be": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0682fece9af849e5a74231002cb52a5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06a8f4e813d14484aae07191437755b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06f50b846e0b4d798f9539d231d8d73e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be9589537dcf44dd8c85d4b624ace520",
      "placeholder": "",
      "style": "IPY_MODEL_5322daad6f874e7ba48f6bf62b01759d",
      "value": "Downloading: 100%"
     }
    },
    "07a6a4a0e60f43af9f38a666210f1408": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "08fceb90f22b4db78f6ce0bed8f4e207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0900ef4eae0b44239dd315e39b327bb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "096aeabf0e7447edbe88d9861a6d9df8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "09d31effa8eb47cead0c7c2694a7081a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0da89b7fdaa24b20891b354d5acf11d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2076819162704754ab115426184105e8",
       "IPY_MODEL_4134f37b33534323b6d1d782e4a084c1",
       "IPY_MODEL_e411978c571e4f5ba1e99c52829884c9"
      ],
      "layout": "IPY_MODEL_14ec36342ba447ab83761b0cd8c241c8"
     }
    },
    "0de17ed106e44ce5a42943edc189fcb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3712a099dd994bbaa077cbd4228b3e40",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_91301ccaa8a44b84a5c1b2b40a30b1a5",
      "value": 1
     }
    },
    "0e266648420c4ea6a1d33677099e825c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be60f1ffaa5c4a28949245b894002faa",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec85a89cfab64e17a7ed792bbe77ad10",
      "value": 5069051
     }
    },
    "0e2dec2610a2414488020a5d1d0ea88a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0e6361baca37459182dbbf8bf62d72a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b134bd89f6ea43f1a1f8b67973732c8d",
      "placeholder": "",
      "style": "IPY_MODEL_31fbe900180742119fb0ccdce059f35e",
      "value": " 4/? [00:01&lt;00:00,  2.41it/s]"
     }
    },
    "0f4d3131dd564abdbc824e4bc9e2928c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0fe466b954204ecd9d33caddf248da52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "104d1062a1b24e29909e86395b7f76f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11c6f20f4ee248d290b735557b5415ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "12221b5946bf4b2ab5a029ffd8a07454": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12263828a3484fd2a40126a2a99096ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12456134939949f7946bb948cc2bd93c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed8804207e074fc5a09f9d59cfbfe2fa",
      "placeholder": "",
      "style": "IPY_MODEL_e55f529fc04942109243e8a274c36d56",
      "value": " 9/? [00:06&lt;00:00,  1.52it/s]"
     }
    },
    "1327d7b1239f428394c9473fe3a092c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14ec36342ba447ab83761b0cd8c241c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14f924f3402040a08ea05648cc59fd72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16565a3ef2234725b25eb605e7212c22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9371eb27783a42de9846837f448b2634",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd29333790d9487d92b482cd0a9fcc60",
      "value": 1
     }
    },
    "17e1c1d3b74843ba8e0b184ed872c724": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e734fe318b41c6ad2a6817b11735c6",
      "placeholder": "",
      "style": "IPY_MODEL_06a8f4e813d14484aae07191437755b8",
      "value": ""
     }
    },
    "1946cd591496468895125e06f5d1f8c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39796b9134094247a48ce160a6550fe6",
      "placeholder": "",
      "style": "IPY_MODEL_b20668b9b7b2442e9b5aff51efb26e5a",
      "value": "Downloading: 100%"
     }
    },
    "1a84c592c55448b88ff4d4973c451ce6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73a87bcaebcb4390962a62b273c91088",
      "placeholder": "",
      "style": "IPY_MODEL_b883757a551f480e8c5ecb911491ec76",
      "value": "Downloading: 100%"
     }
    },
    "1c3ba1e8c956425a98342a9c57c5afff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c01613112a194d7290eb2ad1736ecc3b",
       "IPY_MODEL_e61231528fe34c3cb842add015f114ad",
       "IPY_MODEL_bcf3045fc06f42dda3236ebd9d00e12c"
      ],
      "layout": "IPY_MODEL_aae3d41ae7c8454181fbd20afcf27940"
     }
    },
    "1c6067a81f7a4e1cb7123c5e6b33be4d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d045d76cf5744c99fdbdd3a9f5d278a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78b3937753b844b5914918ec7b1e0245",
      "placeholder": "",
      "style": "IPY_MODEL_3e9d01b2d70f4571be96377f4063ee8d",
      "value": ""
     }
    },
    "1d1429d702b5408480f6cdf8094f4b3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e5d9ca735054147ac3a856e4abf61a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e9f3e09c4a0467283eb1ffd374f67fc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_07a6a4a0e60f43af9f38a666210f1408",
      "value": 1
     }
    },
    "1f2c04f83cdd4dcd826f122f2dbd50c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63f20b38f41e4d5bbbc5b1ea772ea354",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9a6649aa1a184e7393d263142041ea14",
      "value": 1
     }
    },
    "1f46d337ae324d17aaca039402af302f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33248311785e4710a88003f6fab0e5ff",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a0c958294b364af8b07913eeb2645d7e",
      "value": 1
     }
    },
    "2076819162704754ab115426184105e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c93c197f924244e1ace188a3b9a4d70d",
      "placeholder": "",
      "style": "IPY_MODEL_88474c796c1b4471913e15708b9d95b8",
      "value": ""
     }
    },
    "20d84a687280490d8babe216ccf2b0bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1de70e801584e3bb4e9269d206f8df2",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45e4ddc0bffc41b79e5c475b05b5d9f3",
      "value": 9096718
     }
    },
    "2208d46b54d243b087e48449299a74eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "22854f25cbae42b3884d9c15d2b1c86d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c5db6170f4bb4461a57de21d67cea869",
       "IPY_MODEL_f825d1691d9941b19dc9e3c8f1f09a9a",
       "IPY_MODEL_dbc80c4cb096434d87d0bdeaa961bd22"
      ],
      "layout": "IPY_MODEL_e36d0e0128d8427b9f7d3fcfac59ff1a"
     }
    },
    "22887b1da48f4efe91d70d37b30ecc88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ae2137cb24411a98f2989c18046d7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23ba7435a2df4698b48c88b73327c0d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23cda8e4645747bbaf17201f184f70a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2425de3039334c3a90941aa59e092a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b79225710cee4015894c83d388c3e673",
      "placeholder": "",
      "style": "IPY_MODEL_4254651428ec41548aa59a1ffc90a382",
      "value": " 9/? [00:05&lt;00:00,  1.76it/s]"
     }
    },
    "2448dc0e3d26474a8d474232535c55b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "257858d94c3a4a3da29d81dccb023ebd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_028607648b6546cbaec8cd737fb5f584",
      "placeholder": "",
      "style": "IPY_MODEL_a7a4b53ef5524deea80b444f52acb135",
      "value": " 4/? [00:01&lt;00:00,  3.02it/s]"
     }
    },
    "259572bb29e34d059192c8b7cf17b4dc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25a6787bfe76485f80986e0dbd9be1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "262e6afaf5da41a5976916b55c786add": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "27e6d106679d4fddb3aa31ba458f1087": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29c44eabeaf547a184f70d02c9e9b6b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2a051ae5a8ef4f62a941b2e3892c6a38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2aa88a8c258142ebbc5a843634224474": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b4fd8bac4a74d1bbd244e69678d7aa8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12221b5946bf4b2ab5a029ffd8a07454",
      "placeholder": "",
      "style": "IPY_MODEL_3eb3e2a357104b8a8fcd88a10a5a8fd6",
      "value": "100%"
     }
    },
    "2b628b1c30694495b3cb0eeeea09eff6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b79a72eff5444bba4dc8ed0b8488c0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81aef0cce7d44253800cb502602135e4",
      "max": 513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9a66256a7224d5e8674fbca5703c175",
      "value": 513
     }
    },
    "2b902c865ccf43f0a9e2ae819391a0c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2c55cede827941c3aa2b167db6241912": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4e1e8203e2d64e5b8d961bb8800b83b3",
      "placeholder": "",
      "style": "IPY_MODEL_e0a7a546187148b299ef648197f0853f",
      "value": ""
     }
    },
    "2c62f3b516b840acbf38176e7dea8701": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2cb97ad3be7340cdad444adc4097f1e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ade8aba81d34f4f8d55e7c0e0c9fd08",
      "placeholder": "",
      "style": "IPY_MODEL_8344d7c63f844cd6af5f30f1f914f505",
      "value": ""
     }
    },
    "2d372d8c558944f68c5d831efe66e709": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1cae88538a54a7a9fd225875b5efe12",
       "IPY_MODEL_36240cb00ee74b86b6183225475920e1",
       "IPY_MODEL_c24c279e4c74429f9f0ddbb2f7b4b94b"
      ],
      "layout": "IPY_MODEL_3c46d5daff684c9dafcf257c40a1c33a"
     }
    },
    "2d683ea3f6bc481788f17a2eb98f8de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "2d799e14664e4f71a0e52d002603ae6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4465fde1782d4ae5931a9e2d1cfdd5ef",
      "placeholder": "",
      "style": "IPY_MODEL_a62dafcccde341ddaa23efc711f4baef",
      "value": " 4/? [00:02&lt;00:00,  1.41it/s]"
     }
    },
    "2d9df97006eb4029b08e85fde32aca56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e43d6a5eff446c994fd7b491b2fba55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a7fdfa2ad9b34b739b00741fea65ef60",
       "IPY_MODEL_94ecd667232a402b825f017a0318af8b",
       "IPY_MODEL_ea48400f02c64d6a94277b81c57e2885"
      ],
      "layout": "IPY_MODEL_c6aa5349d29840fbaede343ae9c1394d"
     }
    },
    "2f7f72a029344319af2f7e4662d9d9c0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff8491756f045ae980f1b17aa0de59f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305c662c690d4a8fbdd20fb9727270b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30a92e3e16bf4aa09cde0a794ee99273": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "30ebffabcd2843dab3b47a66f4cacfbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_430bac30e54e4475a3d06f2ae40eb8f2",
      "placeholder": "",
      "style": "IPY_MODEL_fd5c87f273364d6b8b01c7ae0d0d8d60",
      "value": " 5.07M/5.07M [00:00&lt;00:00, 4.71MB/s]"
     }
    },
    "3160f691bf8649d599c5beb5edf16e6a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31f8640659b74b23a7a2467a0dbb9696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "31fbe900180742119fb0ccdce059f35e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3280994730964cc39b553bef74010eeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7405e8f8a7654ccbad6cdbe4ef9e2d3f",
       "IPY_MODEL_2b79a72eff5444bba4dc8ed0b8488c0e",
       "IPY_MODEL_eb035aff4e47418b88f0f41db8388725"
      ],
      "layout": "IPY_MODEL_a5bad952f6dd4a8e80069cd6184aa42f"
     }
    },
    "328348c968b142d38b627033364aea3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33248311785e4710a88003f6fab0e5ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "337003cadee2442ba59494dd6e3131ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "339c896eb8bf470f8161a519894d727a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33b2025ec87c4d1eb666085053cc5250": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35055fc27219499b9160509c670bfbb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "357777cea3fa4abc935f901dbdf1bdf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "359143f61ed24f8481f13480092c5405": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35cb017075724474ad6746745dbd0b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35e4c77a71e54790a57065fb22c5403b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "36240cb00ee74b86b6183225475920e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78e485c399064618b6ad60730f9b2403",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_78c7cc6c3a024a189bfbc7044f89a339",
      "value": 1
     }
    },
    "3634916312a347fe9e6ee9c1d59b770f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5b3c53eb92e4e37aaa171b092828eb2",
      "placeholder": "",
      "style": "IPY_MODEL_9c9c9944454e4370b4426cd97d51af77",
      "value": ""
     }
    },
    "3661a1ad8bbc45a691b4a7c702b5a972": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3712a099dd994bbaa077cbd4228b3e40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3832ea9863dd45deb009574adcc157b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c5af5a0ea534b61a23084b5579e3fcb",
      "placeholder": "",
      "style": "IPY_MODEL_35055fc27219499b9160509c670bfbb4",
      "value": " 2.24G/2.24G [01:08&lt;00:00, 28.3MB/s]"
     }
    },
    "38e734fe318b41c6ad2a6817b11735c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39796b9134094247a48ce160a6550fe6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39c502e381984ee69805b8959f51aec0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_637220cc21214f7c8cf8e4e3444a7fd7",
      "placeholder": "",
      "style": "IPY_MODEL_2aa88a8c258142ebbc5a843634224474",
      "value": ""
     }
    },
    "39eaa7ab6d204e5ca4aa4f50b809312f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_305c662c690d4a8fbdd20fb9727270b7",
      "placeholder": "",
      "style": "IPY_MODEL_ca4167d7ae094dd3b0ff00c283204750",
      "value": ""
     }
    },
    "3a380f3aeff8446581dbee64a6b4609f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3a59fe30158b42989ebb093dd0d7d44b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3b7e34dfd0474b4180277c0260dddca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d0a82b71d800496e8ca6caa0f8c6118f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_040a43c0a80749aa91c84e60c9dc9df1",
      "value": 1
     }
    },
    "3b852c1ccd144b298f87078d46790105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22887b1da48f4efe91d70d37b30ecc88",
      "placeholder": "",
      "style": "IPY_MODEL_9e4c8e4c1b8d42c2a03dba54f5c023a4",
      "value": " 15/? [00:10&lt;00:00,  1.65it/s]"
     }
    },
    "3c46d5daff684c9dafcf257c40a1c33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c7fcc0b4def4a198a631e9ea9683a43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ce8029bc0cd4b1890d458ac51d8fc2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f020c9f836c4b0cbfd1af64855e2793",
      "placeholder": "",
      "style": "IPY_MODEL_3ceca586832a4d0c80ca4d1b709657bd",
      "value": " 4/? [00:01&lt;00:00,  2.01it/s]"
     }
    },
    "3ceca586832a4d0c80ca4d1b709657bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d7648a85843493f9f5ffd83161edcf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d9bf8111fdf4473a0214e73c8f0904f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3e34dfdace3a49388040b30a43a0d44e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3e9d01b2d70f4571be96377f4063ee8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3eb3e2a357104b8a8fcd88a10a5a8fd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3f02c2320b514d519b23112088f429c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "3f861aad8dc9474f84e3f7d5836c37d9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4084d9417542497089d7d9d3a9d4d971": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "40bc13848dcb459392359e060ec053c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40f728677716424c831f61d50cccfb87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88b1d5296f8544949906402844bca853",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03d8bee45e714172852ecb9da7993627",
      "value": 5069051
     }
    },
    "4134f37b33534323b6d1d782e4a084c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d736ab979c6f4f52bd79dfac8859ce9a",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b888f5961e444430b6bc3b163bfa1741",
      "value": 1
     }
    },
    "414962b849174a3fbfe604637f2b21c3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41771e47c8484faca97600bc6a8db761": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4254651428ec41548aa59a1ffc90a382": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "426a6b3aafdd497f8e2bc9a6e30e0c0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42cd3cce293040368855cfdc7b5e1154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "430bac30e54e4475a3d06f2ae40eb8f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "432277a1a34c4e40aa0c46ed5f789f69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "43bd340459f54bab9b7e030e6244075b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4429c9854f564f11815f9725ca9816cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1946cd591496468895125e06f5d1f8c3",
       "IPY_MODEL_20d84a687280490d8babe216ccf2b0bf",
       "IPY_MODEL_a124de9d40914ac193147bfc2301ca98"
      ],
      "layout": "IPY_MODEL_74f601bbfe8d46058339168d18ac85f2"
     }
    },
    "4448c07bd5ce48c78308283e5960c394": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9a5b71477dc4dde9872bc2812b6ee1a",
      "placeholder": "",
      "style": "IPY_MODEL_55d6e3222b1144fc93ea86f100c5a05d",
      "value": " 513/513 [00:00&lt;00:00, 13.7kB/s]"
     }
    },
    "4465fde1782d4ae5931a9e2d1cfdd5ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45e4ddc0bffc41b79e5c475b05b5d9f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "45ed01535f25403c8cd2f00bdb347c5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cc004c8f2b3441cd8d395c9f7778dd3b",
       "IPY_MODEL_9dd37fcca3fc4a6db18785c80e1c5f78",
       "IPY_MODEL_2425de3039334c3a90941aa59e092a12"
      ],
      "layout": "IPY_MODEL_7d40c1f0ca8e4e179345f7f51d00e274"
     }
    },
    "478ad9c8da7544059d3cdcccd0b4040d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "47bfd91a954d4313b8439a1251abece7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "495fbf6c5bf64517b0e029e4caeb500e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6af46d7f33ae4540a63eb7809801d202",
       "IPY_MODEL_0de17ed106e44ce5a42943edc189fcb6",
       "IPY_MODEL_257858d94c3a4a3da29d81dccb023ebd"
      ],
      "layout": "IPY_MODEL_40bc13848dcb459392359e060ec053c8"
     }
    },
    "4a3312b4fff049528a238aaf225f967f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ade8aba81d34f4f8d55e7c0e0c9fd08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b0ced42a14c46e7a999cfe4f0d60292": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b57654c984b4ba6b1994779a7b5de79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96db4ba22cab41629d59b29c629b2b2e",
      "placeholder": "",
      "style": "IPY_MODEL_9686db28a028404cbb08a54461683207",
      "value": " 25/? [00:14&lt;00:00,  2.16it/s]"
     }
    },
    "4bd0b87187db46aebf0f07e257d0da66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c2ac7ce415e471aa13297c53a11bd59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4cb06a9d33b74f8d81d143aa3fe5f35b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4cb39f1096f845408dac2c8114152f1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c9089de303c4f4e84f6345064f5ee6d",
       "IPY_MODEL_9cea9640eee14905bf00876b3be47663",
       "IPY_MODEL_7e8afeacef204fcca5e7f54e60060f5e"
      ],
      "layout": "IPY_MODEL_2ff8491756f045ae980f1b17aa0de59f"
     }
    },
    "4cd09071c48d4006aa68bc82dc75d282": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c6104df63cb41078131d32f779b1284",
      "placeholder": "",
      "style": "IPY_MODEL_42cd3cce293040368855cfdc7b5e1154",
      "value": " 17/? [00:12&lt;00:00,  1.46it/s]"
     }
    },
    "4cfbb061ad3841a3bc783c55da399ed9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d5a68d6937347bcafe23ff3567b7528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "4dbdff8de90549f3a3fd928c9a7e526a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39c502e381984ee69805b8959f51aec0",
       "IPY_MODEL_1e5d9ca735054147ac3a856e4abf61a3",
       "IPY_MODEL_e3b1e3717522402ab689cf386438700c"
      ],
      "layout": "IPY_MODEL_8c74a28b20414789945a017f47550f4f"
     }
    },
    "4e1e8203e2d64e5b8d961bb8800b83b3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4f020c9f836c4b0cbfd1af64855e2793": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4facfe6fe52546d383fee5342433b6e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a1f613618d1e46749425bd8f1f841162",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b7284b074daf4f32ba02d4d95d905307",
      "value": 1
     }
    },
    "4fb8aa04be2b406ea085b9385875fc98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4fcb2693d3214dbb8175394fc0d96e15": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50ec086f5d3f44d98c922ea673db2464": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "51323bde0a324206ba1ee5a8b6e35c66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52ac456567384c2da0e97b4daf6a4479": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5322daad6f874e7ba48f6bf62b01759d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "536d0ca8ad3240babc1a747848383813": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53cc42ffd95b4826ac3591566a81d11e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "55895ac82edb4fe9a24a0a0bc7b4c894": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55d6e3222b1144fc93ea86f100c5a05d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "570af36eef574e41bd33699b8976a503": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58688a4e13584afbaea881a2cf7cec10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2cb97ad3be7340cdad444adc4097f1e3",
       "IPY_MODEL_7d22e6ebdc114497ada4605de2c58d59",
       "IPY_MODEL_6bf1c174ac9b4495b3a066591beada2b"
      ],
      "layout": "IPY_MODEL_1327d7b1239f428394c9473fe3a092c8"
     }
    },
    "58db907bec25432a9cbc04aeec1c205e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dabc1eed01e74ea293c943bfb9ad14ac",
      "placeholder": "",
      "style": "IPY_MODEL_6eff7b047fea4b999d7de6f2481ae768",
      "value": ""
     }
    },
    "58dc1e3b108c448184f4516391d6750c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ddd1e0f5b5b14d77be0c0fa9d3dc53de",
      "placeholder": "",
      "style": "IPY_MODEL_d6ac3035f4fc46bcbb80f6952a982884",
      "value": " 16/? [00:05&lt;00:00,  3.05it/s]"
     }
    },
    "5a42a8d6fb204c0b9e1e7cfd5de6b3ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a051ae5a8ef4f62a941b2e3892c6a38",
      "placeholder": "",
      "style": "IPY_MODEL_e9029752740946fa9e77b19fcf840dc6",
      "value": " 16/? [00:05&lt;00:00,  3.20it/s]"
     }
    },
    "5c2ab7d20b7e43eeb5faa1111f9370c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c06189f026484596922c5099d6be1b8e",
       "IPY_MODEL_0e266648420c4ea6a1d33677099e825c",
       "IPY_MODEL_30ebffabcd2843dab3b47a66f4cacfbd"
      ],
      "layout": "IPY_MODEL_f1e60bf7a6ab4f949965047e901543af"
     }
    },
    "5c5aacc923c643348d11eac30c81b658": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c6104df63cb41078131d32f779b1284": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cda19785cb44507bd3ff1a45f270604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25a6787bfe76485f80986e0dbd9be1f6",
      "placeholder": "",
      "style": "IPY_MODEL_eace8a4075764b62889cc33dd1dec4f1",
      "value": ""
     }
    },
    "5da582397fbf4680ba6e556d8a889090": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d683ea3f6bc481788f17a2eb98f8de2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cc5821db3e4147e2bd749c0f8d450b37",
      "value": 1
     }
    },
    "60e685ab2e6e488f8b9e58a11ffe35f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "6166700b766343bf989bafc730a7d7ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61c88881a39140e998fb1c42fcf4353d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9fea575dbca487b9dd6b04a7bd4143a",
       "IPY_MODEL_aceab5333b98449b80b9b1568ac7aaea",
       "IPY_MODEL_0e6361baca37459182dbbf8bf62d72a0"
      ],
      "layout": "IPY_MODEL_d14309d78a76443c9221a664de5812e4"
     }
    },
    "61e6c0de564344129fb7b4979abc3666": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_84119387961d479e97149d993b598e65",
      "placeholder": "",
      "style": "IPY_MODEL_ae494952f2aa4bc88a94d92c3527daf1",
      "value": " 13/? [00:04&lt;00:00,  3.31it/s]"
     }
    },
    "637220cc21214f7c8cf8e4e3444a7fd7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63f20b38f41e4d5bbbc5b1ea772ea354": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "641d317f1043472ab3d5c25c62e0ae8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "647f595d92f040189ed7bdffe8855fa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ae0a8f582cf3444d9f31daa01d303d46",
       "IPY_MODEL_9d75a33b23294e33be810ed45de2dc1b",
       "IPY_MODEL_9d95de89784d4775bfd62364bee6e9d9"
      ],
      "layout": "IPY_MODEL_14f924f3402040a08ea05648cc59fd72"
     }
    },
    "64fc347b02f94171b7cd22a186781e30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6556e820ac704722b7903254167e430f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6571bcd10bce453380f6d131bc2dea5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "663b2684137e46adb6fc54134c17b350": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94e2fb640e6f48d594aee6b2fe20c408",
       "IPY_MODEL_b36eda2803b9411eb35691db39c59337",
       "IPY_MODEL_3b852c1ccd144b298f87078d46790105"
      ],
      "layout": "IPY_MODEL_23ae2137cb24411a98f2989c18046d7a"
     }
    },
    "6643e46efdb7407684b825dcbc96a6b0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66cdea98ac614e69b0d1f5f8ac13f951": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3e34dfdace3a49388040b30a43a0d44e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8f81cc67befa4445969953c9d8b26a0f",
      "value": 1
     }
    },
    "671e90a0fffb44449a4c2ee5d93fec8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "67a26d9f5adb4278a236adca6c2677e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6839407e4cdf43159ecf9fa2cff97980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6af46d7f33ae4540a63eb7809801d202": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33b2025ec87c4d1eb666085053cc5250",
      "placeholder": "",
      "style": "IPY_MODEL_4c2ac7ce415e471aa13297c53a11bd59",
      "value": ""
     }
    },
    "6bf1c174ac9b4495b3a066591beada2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2d9df97006eb4029b08e85fde32aca56",
      "placeholder": "",
      "style": "IPY_MODEL_c4e300a8eb224cb3829d064b88261eea",
      "value": " 4/? [00:01&lt;00:00,  2.59it/s]"
     }
    },
    "6c9089de303c4f4e84f6345064f5ee6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_76a7856dcc8647159182743e7a3dfaac",
      "placeholder": "",
      "style": "IPY_MODEL_4084d9417542497089d7d9d3a9d4d971",
      "value": ""
     }
    },
    "6edeef790bef4ba8b78278afd32d7a14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39eaa7ab6d204e5ca4aa4f50b809312f",
       "IPY_MODEL_91e0078148344fae82f884a1bc2c6dac",
       "IPY_MODEL_4b57654c984b4ba6b1994779a7b5de79"
      ],
      "layout": "IPY_MODEL_986ec9501c4b49b6867751c3aba5d592"
     }
    },
    "6ef15d55c12d436d8fce0762c4dd7eca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6eff7b047fea4b999d7de6f2481ae768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f05584129c94c3184735a6e5f7a5e41": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f98f87aa5df42f49389fe1830a18528": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f9f720e867b4e149809f64c276f70ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "71a477c368284e3eac967eff2f1b5f19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71e7bce851454a45ba053634f2a3fdf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "73a87bcaebcb4390962a62b273c91088": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7405e8f8a7654ccbad6cdbe4ef9e2d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e1052de422846de94c443deeb1f4a19",
      "placeholder": "",
      "style": "IPY_MODEL_bcc1a727668e4497a2e87b83d666ba84",
      "value": "Downloading: 100%"
     }
    },
    "74505852eed14afdbab8ef4906af3b1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74f601bbfe8d46058339168d18ac85f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "753482707ba74d16a09305a9e2af2f03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7596b6ec9d0840f6804bd06be12a5f0b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "75b0dab2d0ee447c97900b821491459c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "76a7856dcc8647159182743e7a3dfaac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77937db7e91549c6b6b8b3812e64e243": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78b3937753b844b5914918ec7b1e0245": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78c7cc6c3a024a189bfbc7044f89a339": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "78e485c399064618b6ad60730f9b2403": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7bdaf6a083a34503bb02195bad9f423d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d031bdcfd5f0452ca1d3104865fda313",
       "IPY_MODEL_40f728677716424c831f61d50cccfb87",
       "IPY_MODEL_7cdb378dc1e042c5bd755c8ab7549711"
      ],
      "layout": "IPY_MODEL_045560d87382405097639dde6aab8468"
     }
    },
    "7c4fc1f6a61d4c25adf706b170972c37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c90f659974b4f88be0a45d9bf0fa85e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7cc9055938dd4a7b80f02be3a0ac9c6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_337003cadee2442ba59494dd6e3131ac",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67a26d9f5adb4278a236adca6c2677e1",
      "value": 1
     }
    },
    "7cdb378dc1e042c5bd755c8ab7549711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96473d5230194558911ae691f658ee7a",
      "placeholder": "",
      "style": "IPY_MODEL_aa75ea17cff24e78896e72770a75477e",
      "value": " 5.07M/5.07M [00:00&lt;00:00, 6.01MB/s]"
     }
    },
    "7d22e6ebdc114497ada4605de2c58d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_262e6afaf5da41a5976916b55c786add",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f9f720e867b4e149809f64c276f70ef",
      "value": 1
     }
    },
    "7d40c1f0ca8e4e179345f7f51d00e274": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d884bf7662245e0877fc76124b66e84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6166700b766343bf989bafc730a7d7ab",
      "placeholder": "",
      "style": "IPY_MODEL_432277a1a34c4e40aa0c46ed5f789f69",
      "value": " 4/? [00:01&lt;00:00,  3.09it/s]"
     }
    },
    "7e0bdeb0ab1d4f0284f9ea558cdce38f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23cda8e4645747bbaf17201f184f70a6",
      "placeholder": "",
      "style": "IPY_MODEL_11c6f20f4ee248d290b735557b5415ce",
      "value": ""
     }
    },
    "7e1052de422846de94c443deeb1f4a19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e1ea7d4b4454449bec0960459cc9f53": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e4261304a8d4b7dabf9f65ba70b7c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e8afeacef204fcca5e7f54e60060f5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c78bb408f5474dedb9aeb36cf11fe353",
      "placeholder": "",
      "style": "IPY_MODEL_ccb370cce221461a819e8e1d822e98a1",
      "value": " 30/? [00:18&lt;00:00,  1.81it/s]"
     }
    },
    "7e9f3e09c4a0467283eb1ffd374f67fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "7f281043e69746c58e6a2788f0012c07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7f414caddd514211ac49b52b58bfd77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "81aef0cce7d44253800cb502602135e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "822bccb4b6304bbab873c18aac29ddcc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8344d7c63f844cd6af5f30f1f914f505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83a10f859d754220b4bb5894ad0ab92f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_328348c968b142d38b627033364aea3a",
      "placeholder": "",
      "style": "IPY_MODEL_850c74ac86324b63bbc305212502b51f",
      "value": " 12/? [00:07&lt;00:00,  1.77it/s]"
     }
    },
    "84119387961d479e97149d993b598e65": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "846ec7db746f4adeba6e4672eef0891a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_17e1c1d3b74843ba8e0b184ed872c724",
       "IPY_MODEL_055bffbf4c6e45ec8c64af3516387d56",
       "IPY_MODEL_7d884bf7662245e0877fc76124b66e84"
      ],
      "layout": "IPY_MODEL_c6db107c2e3946bd89b14bb34ee6b779"
     }
    },
    "850c74ac86324b63bbc305212502b51f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "858dfb6a7a1645328f19574d13f892a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cfbb061ad3841a3bc783c55da399ed9",
      "placeholder": "",
      "style": "IPY_MODEL_426a6b3aafdd497f8e2bc9a6e30e0c0e",
      "value": ""
     }
    },
    "87ca4a68dee14897b6d7b122ee1bcd8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87fe6b1344f44136b7fddfdad0ab04a2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88474c796c1b4471913e15708b9d95b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88b1d5296f8544949906402844bca853": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88e96bca3f5a4b45a5881234e31df92c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88ed841e041443c397df4c060b0824a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcada27ceac24d758f6fc31a1ecbc944",
      "placeholder": "",
      "style": "IPY_MODEL_29c44eabeaf547a184f70d02c9e9b6b2",
      "value": "100%"
     }
    },
    "8a1dd233b8ec4c869d459611281790e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8b0f11d1ec034ec28d792b6b71644d11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c4c5e1e60884044bb7df1b115fa7f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0900ef4eae0b44239dd315e39b327bb2",
      "placeholder": "",
      "style": "IPY_MODEL_7e4261304a8d4b7dabf9f65ba70b7c6d",
      "value": " 7347/7347 [01:33&lt;00:00, 80.46it/s]"
     }
    },
    "8c74a28b20414789945a017f47550f4f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8da4725509164a72b2552f54a8fb59ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f81cc67befa4445969953c9d8b26a0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f88412ed9d242af9be0fec29653e18f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c5aacc923c643348d11eac30c81b658",
      "max": 2244861551,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2208d46b54d243b087e48449299a74eb",
      "value": 2244861551
     }
    },
    "91301ccaa8a44b84a5c1b2b40a30b1a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "918f0931a4114ee09c6e30b7317114c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "91e0078148344fae82f884a1bc2c6dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31f8640659b74b23a7a2467a0dbb9696",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6556e820ac704722b7903254167e430f",
      "value": 1
     }
    },
    "91e73e98616d4e4bbde76d00464556c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93593049b7a84bd4b802fac3598ff700": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93614bdaf09a4d199e88e956a4d442cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9362fc344e3b4a1a881a9d7a4718f3d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f861aad8dc9474f84e3f7d5836c37d9",
      "placeholder": "",
      "style": "IPY_MODEL_4fb8aa04be2b406ea085b9385875fc98",
      "value": " 4/? [00:01&lt;00:00,  2.74it/s]"
     }
    },
    "9371eb27783a42de9846837f448b2634": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "943cf03c372241d0be5a6d3a4451af6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9e6bc8678d64dc58e01d6a1f5571ca7",
      "placeholder": "",
      "style": "IPY_MODEL_ff4a53d7670a4021a9b8a6179b24a37c",
      "value": ""
     }
    },
    "94e2fb640e6f48d594aee6b2fe20c408": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87fe6b1344f44136b7fddfdad0ab04a2",
      "placeholder": "",
      "style": "IPY_MODEL_adca99c9ba6e47e399a9a96d4df13c1a",
      "value": ""
     }
    },
    "94ecd667232a402b825f017a0318af8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d5a68d6937347bcafe23ff3567b7528",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8da4725509164a72b2552f54a8fb59ae",
      "value": 1
     }
    },
    "954283fe5e0e415b9845f216cc6819b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_339c896eb8bf470f8161a519894d727a",
      "placeholder": "",
      "style": "IPY_MODEL_a1cb2840011547199cd8ee370d2b3c50",
      "value": ""
     }
    },
    "96375517c09545c6802ec8b300699728": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96473d5230194558911ae691f658ee7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9686db28a028404cbb08a54461683207": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "96db4ba22cab41629d59b29c629b2b2e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97ca56c9528e41e3af81fffea441bd4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e966f67834bf4c5c930f75c3e2f66b56",
      "max": 9096718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_51323bde0a324206ba1ee5a8b6e35c66",
      "value": 9096718
     }
    },
    "981fc4580f65438496be46ec2831c01d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3160f691bf8649d599c5beb5edf16e6a",
      "placeholder": "",
      "style": "IPY_MODEL_570af36eef574e41bd33699b8976a503",
      "value": " 4/? [00:01&lt;00:00,  2.62it/s]"
     }
    },
    "986ec9501c4b49b6867751c3aba5d592": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a6649aa1a184e7393d263142041ea14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9c5af5a0ea534b61a23084b5579e3fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c9c9944454e4370b4426cd97d51af77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9cea9640eee14905bf00876b3be47663": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6bbc24e654240ccbad8d9502d93862b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_30a92e3e16bf4aa09cde0a794ee99273",
      "value": 1
     }
    },
    "9d75a33b23294e33be810ed45de2dc1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0444bbfb1d5540c8a861fbaa402623a4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a3e2921d5f734b48bb8bda271a827226",
      "value": 1
     }
    },
    "9d95de89784d4775bfd62364bee6e9d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_91e73e98616d4e4bbde76d00464556c5",
      "placeholder": "",
      "style": "IPY_MODEL_3a59fe30158b42989ebb093dd0d7d44b",
      "value": " 6/? [00:03&lt;00:00,  2.06it/s]"
     }
    },
    "9dd37fcca3fc4a6db18785c80e1c5f78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba315b4bee2b4fc89ab9e15b148187fa",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d48e93d6832f4f87a7d2fdaaa275f136",
      "value": 1
     }
    },
    "9e054c86656d4eee8fbc144505d5d679": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e4c8e4c1b8d42c2a03dba54f5c023a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ea1bc73b3444a1a8069231ba5a19f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88ed841e041443c397df4c060b0824a6",
       "IPY_MODEL_cfc417db2337440bbf2f66abe18afe78",
       "IPY_MODEL_e17b2ac3c7d045b4ac2a5ab21cc289b7"
      ],
      "layout": "IPY_MODEL_414962b849174a3fbfe604637f2b21c3"
     }
    },
    "9f51745451ee4ccbb7749fef279171df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a00412489cfd408aaaf49ab5b9d27ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d41129dc02ad4648969676e8aa09801b",
       "IPY_MODEL_f708c667e94b428b88d50134b088ef39",
       "IPY_MODEL_58dc1e3b108c448184f4516391d6750c"
      ],
      "layout": "IPY_MODEL_6571bcd10bce453380f6d131bc2dea5e"
     }
    },
    "a0c958294b364af8b07913eeb2645d7e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a124de9d40914ac193147bfc2301ca98": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75b0dab2d0ee447c97900b821491459c",
      "placeholder": "",
      "style": "IPY_MODEL_ae6e548c851948219aa7798a5434947e",
      "value": " 9.10M/9.10M [00:00&lt;00:00, 20.0MB/s]"
     }
    },
    "a1cae88538a54a7a9fd225875b5efe12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5fdad66b4534a8289143cc7b1610cfe",
      "placeholder": "",
      "style": "IPY_MODEL_6ef15d55c12d436d8fce0762c4dd7eca",
      "value": ""
     }
    },
    "a1cb2840011547199cd8ee370d2b3c50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1f613618d1e46749425bd8f1f841162": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a2271b533d6c4262959bac3ed9e56691": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58db907bec25432a9cbc04aeec1c205e",
       "IPY_MODEL_d6fe30ebf4864b908c7176fdc114f6b5",
       "IPY_MODEL_e067ade55b824ed48dcf4478e2ff60a5"
      ],
      "layout": "IPY_MODEL_1c6067a81f7a4e1cb7123c5e6b33be4d"
     }
    },
    "a2b750dbdd174d0ca1a292b5d0c831d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a394aae326f84efe97b4c7c1c744f43a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3661a1ad8bbc45a691b4a7c702b5a972",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0682fece9af849e5a74231002cb52a5e",
      "value": 1
     }
    },
    "a3bd3c9988684184b9e8be7b189b269f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6f98f87aa5df42f49389fe1830a18528",
      "placeholder": "",
      "style": "IPY_MODEL_c0acbd7e2f974d1e81b866b3f8372d7b",
      "value": " 13/? [00:04&lt;00:00,  3.45it/s]"
     }
    },
    "a3e2921d5f734b48bb8bda271a827226": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5bad952f6dd4a8e80069cd6184aa42f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a62dafcccde341ddaa23efc711f4baef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6752b077f924a5cb9cc859cb3172c18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1d045d76cf5744c99fdbdd3a9f5d278a",
       "IPY_MODEL_eb59193bf7a245c2bb264778ddc41cf1",
       "IPY_MODEL_2d799e14664e4f71a0e52d002603ae6c"
      ],
      "layout": "IPY_MODEL_7c4fc1f6a61d4c25adf706b170972c37"
     }
    },
    "a6bbc24e654240ccbad8d9502d93862b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a6eb1229bf57451797993aae8764b63f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7a4b53ef5524deea80b444f52acb135": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7fdfa2ad9b34b739b00741fea65ef60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6eb1229bf57451797993aae8764b63f",
      "placeholder": "",
      "style": "IPY_MODEL_0fe466b954204ecd9d33caddf248da52",
      "value": ""
     }
    },
    "aa75ea17cff24e78896e72770a75477e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aae08bb8a0df47739cd29b94ca2ff752": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aae3d41ae7c8454181fbd20afcf27940": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aceab5333b98449b80b9b1568ac7aaea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_50ec086f5d3f44d98c922ea673db2464",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_71e7bce851454a45ba053634f2a3fdf1",
      "value": 1
     }
    },
    "adca99c9ba6e47e399a9a96d4df13c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae0a8f582cf3444d9f31daa01d303d46": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12263828a3484fd2a40126a2a99096ff",
      "placeholder": "",
      "style": "IPY_MODEL_b0c4282311394cc8b00954c001b098e5",
      "value": ""
     }
    },
    "ae494952f2aa4bc88a94d92c3527daf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae6e548c851948219aa7798a5434947e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af52104766b44fbbbc9050bd5f040768": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27e6d106679d4fddb3aa31ba458f1087",
      "placeholder": "",
      "style": "IPY_MODEL_7f414caddd514211ac49b52b58bfd77e",
      "value": ""
     }
    },
    "af5717d5ea944b2796266a43908e3e06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0c4282311394cc8b00954c001b098e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b134bd89f6ea43f1a1f8b67973732c8d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b20668b9b7b2442e9b5aff51efb26e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b36eda2803b9411eb35691db39c59337": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_35e4c77a71e54790a57065fb22c5403b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4bd0b87187db46aebf0f07e257d0da66",
      "value": 1
     }
    },
    "b481aba88c084a7a96d7964ef18e5df8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4e71c6ceb6d4414a0125bf20a871c3d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7284b074daf4f32ba02d4d95d905307": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b787a54fc0dc4ba08be8a4c98b27b07e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96375517c09545c6802ec8b300699728",
      "placeholder": "",
      "style": "IPY_MODEL_35cb017075724474ad6746745dbd0b24",
      "value": " 3/? [00:00&lt;00:00,  3.49it/s]"
     }
    },
    "b79225710cee4015894c83d388c3e673": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b883757a551f480e8c5ecb911491ec76": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b888f5961e444430b6bc3b163bfa1741": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b993d655aa5441f781aa9384b669cd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c90f659974b4f88be0a45d9bf0fa85e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e540458c64bd42afa3317de48df7458e",
      "value": 1
     }
    },
    "ba315b4bee2b4fc89ab9e15b148187fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "baaf8a7ccc3b4d999eddfe15909216e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3634916312a347fe9e6ee9c1d59b770f",
       "IPY_MODEL_df62ac011e82419299cad74bf6a77146",
       "IPY_MODEL_4cd09071c48d4006aa68bc82dc75d282"
      ],
      "layout": "IPY_MODEL_1d1429d702b5408480f6cdf8094f4b3b"
     }
    },
    "bacc1fb2d502477fb34f90c453c8b4c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fca481b5c1a84ca9a2b4077bfa0788a6",
       "IPY_MODEL_4facfe6fe52546d383fee5342433b6e2",
       "IPY_MODEL_5a42a8d6fb204c0b9e1e7cfd5de6b3ad"
      ],
      "layout": "IPY_MODEL_6f05584129c94c3184735a6e5f7a5e41"
     }
    },
    "bb7d334cf7424f1f87d8a6b3c87416e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc5c0065de9b45f18bfa214c2a470d24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcada27ceac24d758f6fc31a1ecbc944": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcc1a727668e4497a2e87b83d666ba84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcf3045fc06f42dda3236ebd9d00e12c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c62f3b516b840acbf38176e7dea8701",
      "placeholder": "",
      "style": "IPY_MODEL_08fceb90f22b4db78f6ce0bed8f4e207",
      "value": " 4/? [00:00&lt;00:00,  3.79it/s]"
     }
    },
    "bdebc0d8c5e042e6a2aae324830c233f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_357777cea3fa4abc935f901dbdf1bdf2",
      "placeholder": "",
      "style": "IPY_MODEL_3d7648a85843493f9f5ffd83161edcf5",
      "value": "Downloading: 100%"
     }
    },
    "be60f1ffaa5c4a28949245b894002faa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be9589537dcf44dd8c85d4b624ace520": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c01613112a194d7290eb2ad1736ecc3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_536d0ca8ad3240babc1a747848383813",
      "placeholder": "",
      "style": "IPY_MODEL_af5717d5ea944b2796266a43908e3e06",
      "value": ""
     }
    },
    "c06189f026484596922c5099d6be1b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_753482707ba74d16a09305a9e2af2f03",
      "placeholder": "",
      "style": "IPY_MODEL_822bccb4b6304bbab873c18aac29ddcc",
      "value": "Downloading: 100%"
     }
    },
    "c0acbd7e2f974d1e81b866b3f8372d7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c17032f600a7475facd666bdfe356cbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2b4fd8bac4a74d1bbd244e69678d7aa8",
       "IPY_MODEL_0237d6c8e31b4cb88efc3c554fa503e5",
       "IPY_MODEL_8c4c5e1e60884044bb7df1b115fa7f95"
      ],
      "layout": "IPY_MODEL_74505852eed14afdbab8ef4906af3b1e"
     }
    },
    "c1ed5a249681412aa59a55ea81e4418e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da941db314f94f689096e51697f6c6e5",
       "IPY_MODEL_3b7e34dfd0474b4180277c0260dddca2",
       "IPY_MODEL_12456134939949f7946bb948cc2bd93c"
      ],
      "layout": "IPY_MODEL_3c7fcc0b4def4a198a631e9ea9683a43"
     }
    },
    "c24c279e4c74429f9f0ddbb2f7b4b94b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c4b1def8b09d4be99f31ec9c14f84f51",
      "placeholder": "",
      "style": "IPY_MODEL_096aeabf0e7447edbe88d9861a6d9df8",
      "value": " 15/? [00:09&lt;00:00,  1.89it/s]"
     }
    },
    "c2926566a6464395afcd789a7529d283": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c30a2948dff1476e9551a251a8cad155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4b1def8b09d4be99f31ec9c14f84f51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b667a28b4c4cb18fa8cfa816853b8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c55cede827941c3aa2b167db6241912",
       "IPY_MODEL_a394aae326f84efe97b4c7c1c744f43a",
       "IPY_MODEL_a3bd3c9988684184b9e8be7b189b269f"
      ],
      "layout": "IPY_MODEL_2448dc0e3d26474a8d474232535c55b4"
     }
    },
    "c4e300a8eb224cb3829d064b88261eea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5b3c53eb92e4e37aaa171b092828eb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5db6170f4bb4461a57de21d67cea869": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05bd42bf76cf4a8bb149287688d320be",
      "placeholder": "",
      "style": "IPY_MODEL_43bd340459f54bab9b7e030e6244075b",
      "value": "Downloading: 100%"
     }
    },
    "c6aa5349d29840fbaede343ae9c1394d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6db107c2e3946bd89b14bb34ee6b779": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c78bb408f5474dedb9aeb36cf11fe353": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c93c197f924244e1ace188a3b9a4d70d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9a5b71477dc4dde9872bc2812b6ee1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca3b90cf1715458291d9c8aeb99d6083": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db06646b1f4144d2b004e173c89a0b58",
       "IPY_MODEL_7cc9055938dd4a7b80f02be3a0ac9c6e",
       "IPY_MODEL_9362fc344e3b4a1a881a9d7a4718f3d6"
      ],
      "layout": "IPY_MODEL_da47022cb9184c71bb45874bd2964894"
     }
    },
    "ca4167d7ae094dd3b0ff00c283204750": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc004c8f2b3441cd8d395c9f7778dd3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64fc347b02f94171b7cd22a186781e30",
      "placeholder": "",
      "style": "IPY_MODEL_cd1695bf071644749271f5940d6bca77",
      "value": ""
     }
    },
    "cc5821db3e4147e2bd749c0f8d450b37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ccb370cce221461a819e8e1d822e98a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd1695bf071644749271f5940d6bca77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ceea5f3f020c469693dd241e520ae9bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cfc417db2337440bbf2f66abe18afe78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a3312b4fff049528a238aaf225f967f",
      "max": 11551,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7f281043e69746c58e6a2788f0012c07",
      "value": 11551
     }
    },
    "d031bdcfd5f0452ca1d3104865fda313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6839407e4cdf43159ecf9fa2cff97980",
      "placeholder": "",
      "style": "IPY_MODEL_88e96bca3f5a4b45a5881234e31df92c",
      "value": "Downloading: 100%"
     }
    },
    "d0a82b71d800496e8ca6caa0f8c6118f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d0f266301e3b466486d74faa83c1f38c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d14309d78a76443c9221a664de5812e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1de70e801584e3bb4e9269d206f8df2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2d10d9522c74359a3cb5739f219864f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_af52104766b44fbbbc9050bd5f040768",
       "IPY_MODEL_b993d655aa5441f781aa9384b669cd68",
       "IPY_MODEL_d8bdd0f246684c658d5f5f8b50ea1c4b"
      ],
      "layout": "IPY_MODEL_9e054c86656d4eee8fbc144505d5d679"
     }
    },
    "d41129dc02ad4648969676e8aa09801b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71a477c368284e3eac967eff2f1b5f19",
      "placeholder": "",
      "style": "IPY_MODEL_0f4d3131dd564abdbc824e4bc9e2928c",
      "value": ""
     }
    },
    "d48e93d6832f4f87a7d2fdaaa275f136": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4c67d0789584630871794cf2ce4f47d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_858dfb6a7a1645328f19574d13f892a0",
       "IPY_MODEL_66cdea98ac614e69b0d1f5f8ac13f951",
       "IPY_MODEL_3ce8029bc0cd4b1890d458ac51d8fc2f"
      ],
      "layout": "IPY_MODEL_a2b750dbdd174d0ca1a292b5d0c831d5"
     }
    },
    "d52799201a11466da64c088f9d23d7ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d5680375051b4c06a817a85a5af3a7ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6ac3035f4fc46bcbb80f6952a982884": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6fe30ebf4864b908c7176fdc114f6b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f02c2320b514d519b23112088f429c5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41771e47c8484faca97600bc6a8db761",
      "value": 1
     }
    },
    "d736ab979c6f4f52bd79dfac8859ce9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d7926983f7de44259db6cb4d9a9118d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7e0bdeb0ab1d4f0284f9ea558cdce38f",
       "IPY_MODEL_1f2c04f83cdd4dcd826f122f2dbd50c7",
       "IPY_MODEL_61e6c0de564344129fb7b4979abc3666"
      ],
      "layout": "IPY_MODEL_77937db7e91549c6b6b8b3812e64e243"
     }
    },
    "d8bdd0f246684c658d5f5f8b50ea1c4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93593049b7a84bd4b802fac3598ff700",
      "placeholder": "",
      "style": "IPY_MODEL_2b902c865ccf43f0a9e2ae819391a0c2",
      "value": " 14/? [00:08&lt;00:00,  1.93it/s]"
     }
    },
    "d942a6336a0f42f1aac14aabceecd5cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d9a66256a7224d5e8674fbca5703c175": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d9fea575dbca487b9dd6b04a7bd4143a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f7f72a029344319af2f7e4662d9d9c0",
      "placeholder": "",
      "style": "IPY_MODEL_641d317f1043472ab3d5c25c62e0ae8f",
      "value": ""
     }
    },
    "da47022cb9184c71bb45874bd2964894": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "da941db314f94f689096e51697f6c6e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b0ced42a14c46e7a999cfe4f0d60292",
      "placeholder": "",
      "style": "IPY_MODEL_55895ac82edb4fe9a24a0a0bc7b4c894",
      "value": ""
     }
    },
    "dabc1eed01e74ea293c943bfb9ad14ac": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db06646b1f4144d2b004e173c89a0b58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb9a1b33045a4f5197da06e6ce6501d6",
      "placeholder": "",
      "style": "IPY_MODEL_c2926566a6464395afcd789a7529d283",
      "value": ""
     }
    },
    "db4da210dd184d53a2c92a57671c7d79": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbc80c4cb096434d87d0bdeaa961bd22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ceea5f3f020c469693dd241e520ae9bf",
      "placeholder": "",
      "style": "IPY_MODEL_c30a2948dff1476e9551a251a8cad155",
      "value": " 2.24G/2.24G [01:09&lt;00:00, 21.9MB/s]"
     }
    },
    "dd02219e24904db1840d5ca951ad790d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bdebc0d8c5e042e6a2aae324830c233f",
       "IPY_MODEL_dda3694e69e542f98bc46eb21edf2498",
       "IPY_MODEL_4448c07bd5ce48c78308283e5960c394"
      ],
      "layout": "IPY_MODEL_b4e71c6ceb6d4414a0125bf20a871c3d"
     }
    },
    "dd29333790d9487d92b482cd0a9fcc60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd7d373186794a3c9ac329000694c9f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dda3694e69e542f98bc46eb21edf2498": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03ac9a49e4774957b3c603ab4a7b0f5d",
      "max": 513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_478ad9c8da7544059d3cdcccd0b4040d",
      "value": 513
     }
    },
    "ddd1e0f5b5b14d77be0c0fa9d3dc53de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df62ac011e82419299cad74bf6a77146": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53cc42ffd95b4826ac3591566a81d11e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_671e90a0fffb44449a4c2ee5d93fec8a",
      "value": 1
     }
    },
    "e067ade55b824ed48dcf4478e2ff60a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_87ca4a68dee14897b6d7b122ee1bcd8b",
      "placeholder": "",
      "style": "IPY_MODEL_b481aba88c084a7a96d7964ef18e5df8",
      "value": " 4/? [00:00&lt;00:00,  3.18it/s]"
     }
    },
    "e0a7a546187148b299ef648197f0853f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e17b2ac3c7d045b4ac2a5ab21cc289b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b628b1c30694495b3cb0eeeea09eff6",
      "placeholder": "",
      "style": "IPY_MODEL_bc5c0065de9b45f18bfa214c2a470d24",
      "value": " 11551/11551 [03:25&lt;00:00, 54.60it/s]"
     }
    },
    "e34c2879a0c94f468c41b7896b237d90": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f51745451ee4ccbb7749fef279171df",
      "placeholder": "",
      "style": "IPY_MODEL_d0f266301e3b466486d74faa83c1f38c",
      "value": " 9.10M/9.10M [00:00&lt;00:00, 19.6MB/s]"
     }
    },
    "e36d0e0128d8427b9f7d3fcfac59ff1a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e3b1e3717522402ab689cf386438700c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd7d373186794a3c9ac329000694c9f8",
      "placeholder": "",
      "style": "IPY_MODEL_359143f61ed24f8481f13480092c5405",
      "value": " 13/? [00:04&lt;00:00,  3.68it/s]"
     }
    },
    "e411978c571e4f5ba1e99c52829884c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52ac456567384c2da0e97b4daf6a4479",
      "placeholder": "",
      "style": "IPY_MODEL_104d1062a1b24e29909e86395b7f76f1",
      "value": " 4/? [00:01&lt;00:00,  2.33it/s]"
     }
    },
    "e515382c15a14b4abfe336c0877eaf5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_943cf03c372241d0be5a6d3a4451af6c",
       "IPY_MODEL_1f46d337ae324d17aaca039402af302f",
       "IPY_MODEL_83a10f859d754220b4bb5894ad0ab92f"
      ],
      "layout": "IPY_MODEL_8b0f11d1ec034ec28d792b6b71644d11"
     }
    },
    "e540458c64bd42afa3317de48df7458e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e55f529fc04942109243e8a274c36d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5fdad66b4534a8289143cc7b1610cfe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e61231528fe34c3cb842add015f114ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7596b6ec9d0840f6804bd06be12a5f0b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d52799201a11466da64c088f9d23d7ee",
      "value": 1
     }
    },
    "e9029752740946fa9e77b19fcf840dc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e966f67834bf4c5c930f75c3e2f66b56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea48400f02c64d6a94277b81c57e2885": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_259572bb29e34d059192c8b7cf17b4dc",
      "placeholder": "",
      "style": "IPY_MODEL_0e2dec2610a2414488020a5d1d0ea88a",
      "value": " 4/? [00:02&lt;00:00,  1.53it/s]"
     }
    },
    "eace8a4075764b62889cc33dd1dec4f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb035aff4e47418b88f0f41db8388725": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4fcb2693d3214dbb8175394fc0d96e15",
      "placeholder": "",
      "style": "IPY_MODEL_d5680375051b4c06a817a85a5af3a7ae",
      "value": " 513/513 [00:00&lt;00:00, 12.4kB/s]"
     }
    },
    "eb59193bf7a245c2bb264778ddc41cf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d942a6336a0f42f1aac14aabceecd5cb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_47bfd91a954d4313b8439a1251abece7",
      "value": 1
     }
    },
    "ec85a89cfab64e17a7ed792bbe77ad10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed8804207e074fc5a09f9d59cfbfe2fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed591df093e4080ac746625a0748920": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5cda19785cb44507bd3ff1a45f270604",
       "IPY_MODEL_16565a3ef2234725b25eb605e7212c22",
       "IPY_MODEL_b787a54fc0dc4ba08be8a4c98b27b07e"
      ],
      "layout": "IPY_MODEL_93614bdaf09a4d199e88e956a4d442cb"
     }
    },
    "f1e60bf7a6ab4f949965047e901543af": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f708c667e94b428b88d50134b088ef39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60e685ab2e6e488f8b9e58a11ffe35f0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3a380f3aeff8446581dbee64a6b4609f",
      "value": 1
     }
    },
    "f825d1691d9941b19dc9e3c8f1f09a9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aae08bb8a0df47739cd29b94ca2ff752",
      "max": 2244861551,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4cb06a9d33b74f8d81d143aa3fe5f35b",
      "value": 2244861551
     }
    },
    "f9e6bc8678d64dc58e01d6a1f5571ca7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb9a1b33045a4f5197da06e6ce6501d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fca481b5c1a84ca9a2b4077bfa0788a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23ba7435a2df4698b48c88b73327c0d6",
      "placeholder": "",
      "style": "IPY_MODEL_918f0931a4114ee09c6e30b7317114c0",
      "value": ""
     }
    },
    "fd5c87f273364d6b8b01c7ae0d0d8d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff4a53d7670a4021a9b8a6179b24a37c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
