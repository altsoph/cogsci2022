{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "\n",
    "from collections import defaultdict #, Counter\n",
    "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
    "\n",
    "from operator import mul\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "device = 'cuda:0'\n",
    "softmax = torch.nn.Softmax(dim=-1)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-uncased'\n",
    "MASK_TOKEN = '[MASK]'\n",
    "PAD_TOKEN = '[PAD]'\n",
    "BOS_TOKEN = '[CLS]'\n",
    "EOS_TOKEN = '[SEP]'\n",
    "\n",
    "KWORDS_THING = ('quoi que ce soit','quoi que ce soit','quoi que ce soit','quoi que ce soit')\n",
    "KWORDS_BODY  = ('qui que ce soit','qui que ce soit','qui que ce soit','qui que ce soit')\n",
    "INPUT_FILE = 'fr_test_sentences_newwords.tsv'\n",
    "\n",
    "PREFIX = 'fr_mbert'\n",
    "\n",
    "BATCH_SIZE = 40 \n",
    "assert BATCH_SIZE%4 == 0, '# important to have BATCH_SIZE%4 == 0'\n",
    "\n",
    "RANDOM_TOKENS = 40\n",
    "\n",
    "keywords = list(set(KWORDS_THING)|set(KWORDS_BODY))\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.add_tokens(['[NOT]','[FEW]','[MANY]'], special_tokens=True)\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME)\n",
    "device = torch.device('cuda:0')\n",
    "model.to(device)\n",
    "reverse_vocab = {y:x for x, y in tokenizer.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ['quoi', 'que', 'ce', 'soit']\n",
      "4 ['qui', 'que', 'ce', 'soit']\n"
     ]
    }
   ],
   "source": [
    "# let's check the number of tokens in our keywords\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "keywords2tokens = dict()\n",
    "\n",
    "for keyword in keywords:\n",
    "    tokens = tokenizer.tokenize(keyword)\n",
    "    keywords2tokens[keyword] = tokens\n",
    "#     keywords2random_tokens[keyword] = np.random.choice(range(max(reverse_vocab)), (TEST_CASES_PER_SIZE,len(tokens)))\n",
    "    print(len(tokens), tokens)\n",
    "\n",
    "random_tokens = dict()\n",
    "for tok in ('[NOT]', '[FEW]', '[MANY]'):\n",
    "    random_tokens[tok] = np.random.choice(range(max(reverse_vocab)), RANDOM_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[NOT]': array([ 68268,  43567,  42613,  45891,  21243,  95939,  97639,  41993,\n",
       "         86293,  55026,  80471,  80966,  48600,  39512,  52620,  80186,\n",
       "         17089,  32230,  18983,  89688, 101201,  82457,  93005, 104520,\n",
       "          6921,  38804,  67699,  70608,  37619,   7877,  83966,   1871,\n",
       "         73135,   2496,  47954,  24675,  31921,  99059,    797,  49811]),\n",
       " '[FEW]': array([68755, 80782, 90535, 81857, 52489, 84665, 41504, 49866, 84212,\n",
       "        96766, 11723, 43890, 17591, 58146, 92288, 59300, 89141, 71557,\n",
       "        20006,  3560, 90868, 61713, 96591, 45444, 46522, 86904, 20737,\n",
       "        28647, 61353, 92217, 80163, 12134, 60535, 47883, 86107, 63360,\n",
       "        51811,  9781, 19340, 27257]),\n",
       " '[MANY]': array([ 16298,  12372,   4420, 105412,  82991,  62079,  79860, 103555,\n",
       "          7012,   9396,   3918,   9359,  44259,  23482,  15127, 101261,\n",
       "         37237,  79701,   8752,  80041,  71331,  50624,  89183,  40133,\n",
       "         93790,  55153, 102066,  62756,  90928,  81757,  84355,  99938,\n",
       "         48682,  66509,  86384,  75751,  76693,  24777,  13824,   2418])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse, mask, tokenize\n",
    "\n",
    "subj_dict = dict()\n",
    "verb_dict = dict()\n",
    "\n",
    "def mask_sent(sent, kword):\n",
    "    return [BOS_TOKEN,] + tokenizer.tokenize( \n",
    "        sent.replace(kword, f'{MASK_TOKEN} '*len(keywords2tokens[kword])).replace('  ',' ') \n",
    "    ) + [EOS_TOKEN,]\n",
    "\n",
    "tokenized_array = []\n",
    "metadata_array = []\n",
    "\n",
    "lines = [line for idx, line in enumerate(open(INPUT_FILE, encoding='utf-8'))]\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.shuffle(lines)\n",
    "\n",
    "for idx, line in enumerate(lines):\n",
    "    chunks = line.strip().split()\n",
    "    tchunks = line.strip().split('\\t')\n",
    "\n",
    "    if chunks[-1]=='thing':\n",
    "        kwords = KWORDS_THING\n",
    "    else:\n",
    "        kwords = KWORDS_BODY\n",
    "    \n",
    "    subj_id = int(chunks[-3])\n",
    "    subject = chunks[1]\n",
    "    subj_dict[subj_id] = subject\n",
    "    verb_id = int(chunks[-2])\n",
    "    verb1 = chunks[2]\n",
    "    verb2 = chunks[8]\n",
    "    verb_dict[verb_id] = (verb1, verb2)\n",
    "    \n",
    "    for tidx, (cl,kword) in enumerate( zip( ('aff', 'neg', 'many', 'few'), kwords ) ):\n",
    "        mt_sent = mask_sent(tchunks[tidx], kword)\n",
    "        tokenized_array.append( mt_sent )\n",
    "        metadata_array.append( \n",
    "            (\n",
    "                (cl, subj_id, verb_id, kword, chunks[-1]),\n",
    "                (tchunks[tidx], mt_sent)\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5.657305657259036e-16,\n",
       " 7.350508392487928e-15,\n",
       " 2.0825095060433558e-15,\n",
       " 4.913716344780052e-15,\n",
       " 9.683557719052586e-17,\n",
       " 7.360538178429063e-15,\n",
       " 6.350888617272028e-15,\n",
       " 1.4164861795435228e-14]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assess_batch(batch, metas, r_idx):\n",
    "    global scores\n",
    "    batch_input_ids = []\n",
    "    batch_segment_ids = []\n",
    "    \n",
    "    mask_positions = []\n",
    "    mask_lens = []\n",
    "\n",
    "    max_len = max(map(len,batch))\n",
    "    \n",
    "    for idx, s in enumerate(batch):\n",
    "        mask_positions.append( s.index(MASK_TOKEN) )\n",
    "        mask_lens.append( s.count(MASK_TOKEN) )\n",
    "        \n",
    "        input_ids = tokenizer.convert_tokens_to_ids(s + [PAD_TOKEN,]*(max_len-len(s)))\n",
    "        for tok in ('[NOT]', '[FEW]', '[MANY]'): # replace spec tokens with random ones\n",
    "            if tok in s:\n",
    "                input_ids[s.index(tok)] = random_tokens[tok][r_idx]\n",
    "\n",
    "        batch_input_ids.append( input_ids )\n",
    "        batch_segment_ids.append( [0] * len(input_ids) )\n",
    "\n",
    "    input_ids = torch.tensor(batch_input_ids, dtype=torch.long).to(device)\n",
    "    segment_ids = torch.tensor(batch_segment_ids, dtype=torch.long).to(device)\n",
    "    logits = model(input_ids, token_type_ids=segment_ids)[0]\n",
    "    probs = softmax(logits)\n",
    "    \n",
    "    return [\n",
    "        reduce(mul, [pr[pos+t_pos][tokenizer.vocab[tok]].cpu().detach().numpy() \\\n",
    "            for t_pos, tok in enumerate(keywords2tokens[meta[0][3]]) ], 1. ) \\\n",
    "                for pr, pos, meta in zip(probs, mask_positions, metas)\n",
    "    ]\n",
    "        \n",
    "assess_batch(tokenized_array[128*4:130*4], metadata_array[126*4:130*4], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00%\n",
      "0.50%\n",
      "1.00%\n",
      "1.50%\n",
      "2.00%\n",
      "2.50%\n",
      "3.00%\n",
      "3.50%\n",
      "4.00%\n",
      "4.50%\n",
      "5.00%\n",
      "5.50%\n",
      "6.00%\n",
      "6.50%\n",
      "7.00%\n",
      "7.50%\n",
      "8.00%\n",
      "8.50%\n",
      "9.00%\n",
      "9.50%\n",
      "10.00%\n",
      "10.50%\n",
      "11.00%\n",
      "11.50%\n",
      "12.00%\n",
      "12.50%\n",
      "13.00%\n",
      "13.50%\n",
      "14.00%\n",
      "14.50%\n",
      "15.00%\n",
      "15.50%\n",
      "16.00%\n",
      "16.50%\n",
      "17.00%\n",
      "17.50%\n",
      "18.00%\n",
      "18.50%\n",
      "19.00%\n",
      "19.50%\n",
      "20.00%\n",
      "20.50%\n",
      "21.00%\n",
      "21.50%\n",
      "22.00%\n",
      "22.50%\n",
      "23.00%\n",
      "23.50%\n",
      "24.00%\n",
      "24.50%\n",
      "25.00%\n",
      "25.50%\n",
      "26.00%\n",
      "26.50%\n",
      "27.00%\n",
      "27.50%\n",
      "28.00%\n",
      "28.50%\n",
      "29.00%\n",
      "29.50%\n",
      "30.00%\n",
      "30.50%\n",
      "31.00%\n",
      "31.50%\n",
      "32.00%\n",
      "32.50%\n",
      "33.00%\n",
      "33.50%\n",
      "34.00%\n",
      "34.50%\n",
      "35.00%\n",
      "35.50%\n",
      "36.00%\n",
      "36.50%\n",
      "37.00%\n",
      "37.50%\n",
      "38.00%\n",
      "38.50%\n",
      "39.00%\n",
      "39.50%\n",
      "40.00%\n",
      "40.50%\n",
      "41.00%\n",
      "41.50%\n",
      "42.00%\n",
      "42.50%\n",
      "43.00%\n",
      "43.50%\n",
      "44.00%\n",
      "44.50%\n",
      "45.00%\n",
      "45.50%\n",
      "46.00%\n",
      "46.50%\n",
      "47.00%\n",
      "47.50%\n",
      "48.00%\n",
      "48.50%\n",
      "49.00%\n",
      "49.50%\n",
      "50.00%\n",
      "50.50%\n",
      "51.00%\n",
      "51.50%\n",
      "52.00%\n",
      "52.50%\n",
      "53.00%\n",
      "53.50%\n",
      "54.00%\n",
      "54.50%\n",
      "55.00%\n",
      "55.50%\n",
      "56.00%\n",
      "56.50%\n",
      "57.00%\n",
      "57.50%\n",
      "58.00%\n",
      "58.50%\n",
      "59.00%\n",
      "59.50%\n",
      "60.00%\n",
      "60.50%\n",
      "61.00%\n",
      "61.50%\n",
      "62.00%\n",
      "62.50%\n",
      "63.00%\n",
      "63.50%\n",
      "64.00%\n",
      "64.50%\n",
      "65.00%\n",
      "65.50%\n",
      "66.00%\n",
      "66.50%\n",
      "67.00%\n",
      "67.50%\n",
      "68.00%\n",
      "68.50%\n",
      "69.00%\n",
      "69.50%\n",
      "70.00%\n",
      "70.50%\n",
      "71.00%\n",
      "71.50%\n",
      "72.00%\n",
      "72.50%\n",
      "73.00%\n",
      "73.50%\n",
      "74.00%\n",
      "74.50%\n",
      "75.00%\n",
      "75.50%\n",
      "76.00%\n",
      "76.50%\n",
      "77.00%\n",
      "77.50%\n",
      "78.00%\n",
      "78.50%\n",
      "79.00%\n",
      "79.50%\n",
      "80.00%\n",
      "80.50%\n",
      "81.00%\n",
      "81.50%\n",
      "82.00%\n",
      "82.50%\n",
      "83.00%\n",
      "83.50%\n",
      "84.00%\n",
      "84.50%\n",
      "85.00%\n",
      "85.50%\n",
      "86.00%\n",
      "86.50%\n",
      "87.00%\n",
      "87.50%\n",
      "88.00%\n",
      "88.50%\n",
      "89.00%\n",
      "89.50%\n",
      "90.00%\n",
      "90.50%\n",
      "91.00%\n",
      "91.50%\n",
      "92.00%\n",
      "92.50%\n",
      "93.00%\n",
      "93.50%\n",
      "94.00%\n",
      "94.50%\n",
      "95.00%\n",
      "95.50%\n",
      "96.00%\n",
      "96.50%\n",
      "97.00%\n",
      "97.50%\n",
      "98.00%\n",
      "98.50%\n",
      "99.00%\n",
      "99.50%\n"
     ]
    }
   ],
   "source": [
    "# assess all the sentences\n",
    "\n",
    "scores = defaultdict(list)\n",
    "for b_idx, idx in enumerate(range(0, len(tokenized_array), BATCH_SIZE)):\n",
    "    if not idx%200: print(f'{idx/(len(tokenized_array)):.2%}')\n",
    "    scores[b_idx%RANDOM_TOKENS].extend( assess_batch(tokenized_array[idx:idx+BATCH_SIZE], \n",
    "                                                     metadata_array[idx:idx+BATCH_SIZE], \n",
    "                                                     b_idx%RANDOM_TOKENS) ) # here we select the set of random tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(scores).shape\n",
    "len(scores)\n",
    "len(scores[39])\n",
    "\n",
    "# shape of score is [random_tokens_idx][ (aff_prob, neg_prob, many_prob, few_prob)*items ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(lambda:defaultdict(lambda:defaultdict(list)))\n",
    "\n",
    "for r_idx in range(RANDOM_TOKENS):\n",
    "    for score, meta in zip(scores[r_idx], metadata_array):\n",
    "        if meta[0][0]=='aff':\n",
    "            handle = (meta[0][4], 'aff>neg')\n",
    "            k_idx = 0\n",
    "        if meta[0][0]=='neg':\n",
    "            handle = (meta[0][4], 'aff>neg')\n",
    "            k_idx = 1\n",
    "        if meta[0][0]=='many':\n",
    "            handle = (meta[0][4], 'many>few')\n",
    "            k_idx = 0\n",
    "        if meta[0][0]=='few':\n",
    "            handle = (meta[0][4], 'many>few')\n",
    "            k_idx = 1\n",
    "        handle2 = ('both', handle[1])\n",
    "        stats[handle][r_idx][k_idx].append( score )\n",
    "        stats[handle2][r_idx][k_idx].append( score )\n",
    "\n",
    "# shape of stats now is\n",
    "#  [handles][random_tokens_idx][(0 for aff and many, 1 for neg and few)][items]\n",
    "# where handle is one of ('body', 'aff>neg'), ('body', 'many>few'), ('both', 'aff>neg'), \n",
    "#                          ('both', 'many>few'), ('thing', 'aff>neg'), ('thing', 'many>few')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('both', 'aff>neg')   mean 26.160% std 18.506%\n",
      "('both', 'many>few')   mean 52.640% std 27.351%\n",
      "('thing', 'aff>neg')   mean 26.160% std 18.506%\n",
      "('thing', 'many>few')   mean 52.640% std 27.351%\n"
     ]
    }
   ],
   "source": [
    "measures = dict()\n",
    "for handle in sorted(stats):\n",
    "    r = []\n",
    "    for r_idx in range(RANDOM_TOKENS):\n",
    "        r.append( np.count_nonzero(list(map(lambda x:x[0]>x[1], zip(stats[handle][r_idx][0],stats[handle][r_idx][1]))))/len(stats[handle][r_idx][0]) )\n",
    "    print(handle, f'  mean {np.mean(r):0.3%} std {np.std(r):0.3%}')\n",
    "    measures[handle] = r[:]\n",
    "    \n",
    "# shape of measures is \n",
    "#   [handles][ random_tokens_idx scores ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('both', 'aff>neg'), ('both', 'many>few'), ('thing', 'aff>neg'), ('thing', 'many>few')])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r\n",
    "plt.hist(measures[('both', 'aff>neg')])\n",
    "plt.suptitle(str(('both', 'aff>neg')))\n",
    "measures.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('both', 'aff>neg'), ('both', 'many>few'), ('thing', 'aff>neg'), ('thing', 'many>few')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# r\n",
    "plt.hist(measures[('both', 'many>few')])\n",
    "plt.suptitle(str(('both', 'many>few')))\n",
    "measures.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle\n",
    "import dill\n",
    "\n",
    "with open(f'{PREFIX}_baseline_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(scores, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(f'{PREFIX}_baseline_stats.pkl', 'wb') as f:\n",
    "    dill.dump(stats, f)\n",
    "with open(f'{PREFIX}_baseline_measures.pkl', 'wb') as f:\n",
    "    pickle.dump(measures, f, pickle.HIGHEST_PROTOCOL)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('both', 'aff>neg'): [0.084,\n",
       "  0.288,\n",
       "  0.336,\n",
       "  0.032,\n",
       "  0.008,\n",
       "  0.064,\n",
       "  0.552,\n",
       "  0.056,\n",
       "  0.256,\n",
       "  0.276,\n",
       "  0.34,\n",
       "  0.052,\n",
       "  0.184,\n",
       "  0.068,\n",
       "  0.052,\n",
       "  0.408,\n",
       "  0.272,\n",
       "  0.304,\n",
       "  0.144,\n",
       "  0.472,\n",
       "  0.612,\n",
       "  0.304,\n",
       "  0.252,\n",
       "  0.648,\n",
       "  0.376,\n",
       "  0.116,\n",
       "  0.308,\n",
       "  0.476,\n",
       "  0.336,\n",
       "  0.208,\n",
       "  0.26,\n",
       "  0.572,\n",
       "  0.056,\n",
       "  0.04,\n",
       "  0.088,\n",
       "  0.008,\n",
       "  0.236,\n",
       "  0.6,\n",
       "  0.204,\n",
       "  0.516],\n",
       " ('both', 'many>few'): [0.896,\n",
       "  0.656,\n",
       "  0.172,\n",
       "  0.268,\n",
       "  0.48,\n",
       "  0.344,\n",
       "  0.532,\n",
       "  0.436,\n",
       "  0.956,\n",
       "  0.864,\n",
       "  0.3,\n",
       "  0.052,\n",
       "  0.828,\n",
       "  0.056,\n",
       "  0.576,\n",
       "  0.436,\n",
       "  0.916,\n",
       "  0.54,\n",
       "  0.488,\n",
       "  0.616,\n",
       "  0.292,\n",
       "  0.764,\n",
       "  0.028,\n",
       "  0.396,\n",
       "  0.724,\n",
       "  0.268,\n",
       "  0.108,\n",
       "  0.86,\n",
       "  0.82,\n",
       "  0.56,\n",
       "  0.212,\n",
       "  0.024,\n",
       "  0.832,\n",
       "  0.604,\n",
       "  0.768,\n",
       "  0.756,\n",
       "  0.696,\n",
       "  0.452,\n",
       "  0.732,\n",
       "  0.748],\n",
       " ('thing', 'aff>neg'): [0.084,\n",
       "  0.288,\n",
       "  0.336,\n",
       "  0.032,\n",
       "  0.008,\n",
       "  0.064,\n",
       "  0.552,\n",
       "  0.056,\n",
       "  0.256,\n",
       "  0.276,\n",
       "  0.34,\n",
       "  0.052,\n",
       "  0.184,\n",
       "  0.068,\n",
       "  0.052,\n",
       "  0.408,\n",
       "  0.272,\n",
       "  0.304,\n",
       "  0.144,\n",
       "  0.472,\n",
       "  0.612,\n",
       "  0.304,\n",
       "  0.252,\n",
       "  0.648,\n",
       "  0.376,\n",
       "  0.116,\n",
       "  0.308,\n",
       "  0.476,\n",
       "  0.336,\n",
       "  0.208,\n",
       "  0.26,\n",
       "  0.572,\n",
       "  0.056,\n",
       "  0.04,\n",
       "  0.088,\n",
       "  0.008,\n",
       "  0.236,\n",
       "  0.6,\n",
       "  0.204,\n",
       "  0.516],\n",
       " ('thing', 'many>few'): [0.896,\n",
       "  0.656,\n",
       "  0.172,\n",
       "  0.268,\n",
       "  0.48,\n",
       "  0.344,\n",
       "  0.532,\n",
       "  0.436,\n",
       "  0.956,\n",
       "  0.864,\n",
       "  0.3,\n",
       "  0.052,\n",
       "  0.828,\n",
       "  0.056,\n",
       "  0.576,\n",
       "  0.436,\n",
       "  0.916,\n",
       "  0.54,\n",
       "  0.488,\n",
       "  0.616,\n",
       "  0.292,\n",
       "  0.764,\n",
       "  0.028,\n",
       "  0.396,\n",
       "  0.724,\n",
       "  0.268,\n",
       "  0.108,\n",
       "  0.86,\n",
       "  0.82,\n",
       "  0.56,\n",
       "  0.212,\n",
       "  0.024,\n",
       "  0.832,\n",
       "  0.604,\n",
       "  0.768,\n",
       "  0.756,\n",
       "  0.696,\n",
       "  0.452,\n",
       "  0.732,\n",
       "  0.748]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    import cPickle as pickle\n",
    "except ModuleNotFoundError:\n",
    "    import pickle\n",
    "import dill\n",
    "\n",
    "with open(f'{PREFIX}_baseline_measures.pkl', 'rb') as f:\n",
    "#     pickle.dump(measures, f, pickle.HIGHEST_PROTOCOL)        \n",
    "    a = pickle.load(f)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, \"('both', 'aff>neg')\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(a[('both', 'aff>neg')], range=(0,1))\n",
    "plt.suptitle(str(('both', 'aff>neg')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
